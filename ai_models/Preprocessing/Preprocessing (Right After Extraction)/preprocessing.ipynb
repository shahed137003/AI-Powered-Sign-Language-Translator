{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5836f5cc",
   "metadata": {},
   "source": [
    "# Pose-based Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de4b4109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files found: 11980\n",
      "Loaded samples: 11980\n",
      "labels: 11980\n",
      "Number of labels: 11980\n",
      "First sample shape: (74, 438)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "data_path = \"landmarks_mapped/landmarks_mapped\"  \n",
    "\n",
    "# List all .npy files\n",
    "files = glob.glob(os.path.join(data_path, \"*.npy\"))\n",
    "\n",
    "print(\"Total files found:\", len(files))\n",
    "\n",
    "data = []\n",
    "labels =[]  # Using a set to avoid repeated labels\n",
    "\n",
    "for file in files:\n",
    "    # Load npy file\n",
    "    arr = np.load(file, allow_pickle=True)\n",
    "    data.append(arr)\n",
    "\n",
    "    filename = os.path.basename(file)      \n",
    "    label = filename.split(\"_\")[0]           \n",
    "    label = label.split(\".\")[0]              \n",
    "    labels.append(label)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Loaded samples:\", len(data))\n",
    "print(\"labels:\", len(labels))\n",
    "print(\"Number of labels:\", len(labels))\n",
    "print(\"First sample shape:\", data[0].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc80592",
   "metadata": {},
   "source": [
    "## Preprocessing Stage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95679d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First video shapes:\n",
      "Pose: (74, 132)\n",
      "Face: (74, 180)\n",
      "Left hand: (74, 63)\n",
      "Right hand: (74, 63)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "pose_videos = []\n",
    "face_videos = []\n",
    "lh_videos = []\n",
    "rh_videos = []\n",
    "\n",
    "for video in data:\n",
    "    # Split along the last dimension (feature_dim)\n",
    "    pose_videos.append(video[:, 0:132])\n",
    "    face_videos.append(video[:, 132:312])\n",
    "    lh_videos.append(video[:, 312:375])\n",
    "    rh_videos.append(video[:, 375:438])\n",
    "\n",
    "# Check shapes of the first video\n",
    "print(\"First video shapes:\")\n",
    "print(\"Pose:\", pose_videos[0].shape)\n",
    "print(\"Face:\", face_videos[0].shape)\n",
    "print(\"Left hand:\", lh_videos[0].shape)\n",
    "print(\"Right hand:\", rh_videos[0].shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34bac58",
   "metadata": {},
   "source": [
    "### Hand reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd7a912",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def initialize_first_last_flat(hand_frames):\n",
    "    \"\"\"\n",
    "    hand_frames: (T, F) where F = 63 flattened features\n",
    "    Missing hand = all zeros\n",
    "    \"\"\"\n",
    "\n",
    "    T = len(hand_frames)\n",
    "\n",
    "    # find indices with valid (non-zero) hand detections\n",
    "    detected = [i for i in range(T) if not np.all(hand_frames[i] == 0)]\n",
    "\n",
    "    if len(detected) == 0:\n",
    "        return hand_frames  # nothing to reconstruct\n",
    "\n",
    "    # average detected hand frames\n",
    "    avg_hand = np.mean([hand_frames[i] for i in detected], axis=0)\n",
    "\n",
    "    # first frame\n",
    "    if np.all(hand_frames[0] == 0):\n",
    "        hand_frames[0] = avg_hand\n",
    "\n",
    "    # last frame\n",
    "    if np.all(hand_frames[-1] == 0):\n",
    "        hand_frames[-1] = avg_hand\n",
    "\n",
    "    return hand_frames\n",
    "\n",
    "\n",
    "def reconstruct_hands_flat(hand_frames):\n",
    "    \"\"\"\n",
    "    Bilinear interpolation for flattened hand features.\n",
    "    hand_frames: (T, F) where F = 63\n",
    "    \"\"\"\n",
    "\n",
    "    hand_frames = initialize_first_last_flat(hand_frames)\n",
    "    T = len(hand_frames)\n",
    "\n",
    "    for k in range(T):\n",
    "        if not np.all(hand_frames[k] == 0):\n",
    "            continue \n",
    "\n",
    "        \n",
    "        a = 1\n",
    "        while k - a >= 0 and np.all(hand_frames[k - a] == 0):\n",
    "            a += 1\n",
    "\n",
    "        # find next non-zero frame\n",
    "        b = 1\n",
    "        while k + b < T and np.all(hand_frames[k + b] == 0):\n",
    "            b += 1\n",
    "\n",
    "        \n",
    "        if k - a < 0 or k + b >= T:\n",
    "            continue\n",
    "\n",
    "        prev_frame = hand_frames[k - a]\n",
    "        next_frame = hand_frames[k + b]\n",
    "\n",
    "        \n",
    "        hand_frames[k] = (b * prev_frame + a * next_frame) / (a + b)\n",
    "\n",
    "    return hand_frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0835d743",
   "metadata": {},
   "outputs": [],
   "source": [
    "lh_reconstructed=[]\n",
    "for lh_video in lh_videos:\n",
    "    lh_reconstructed.append((lh_video))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "145dee87",
   "metadata": {},
   "outputs": [],
   "source": [
    "rh_reconstructed=[]\n",
    "for rh_video in rh_videos:\n",
    "    rh_reconstructed.append(reconstruct_hands_flat(rh_video))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e98625c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------------------------------\n",
    "# 1) Small random noise (jitter)\n",
    "# --------------------------------------------------\n",
    "def augment_jitter(seq, sigma=0.01):\n",
    "    noise = np.random.normal(0, sigma, seq.shape)\n",
    "    return seq + noise\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 2) Random scaling\n",
    "# --------------------------------------------------\n",
    "def augment_scaling(seq, scale_range=(0.95, 1.05)):\n",
    "    scale = np.random.uniform(*scale_range)\n",
    "    return seq * scale\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 3) Small random rotation\n",
    "# Only rotates (x,y) pairs, not the entire 438-vector blindly.\n",
    "# --------------------------------------------------\n",
    "def augment_rotation(seq, angle_range=(-5, 5)):\n",
    "    angle = np.radians(np.random.uniform(*angle_range))\n",
    "    cos_a, sin_a = np.cos(angle), np.sin(angle)\n",
    "\n",
    "    seq_rot = seq.copy()\n",
    "    reshaped = seq.reshape(seq.shape[0], -1, 2)\n",
    "\n",
    "    for t in range(len(reshaped)):\n",
    "        x = reshaped[t][:, 0]\n",
    "        y = reshaped[t][:, 1]\n",
    "        reshaped[t][:, 0] = x * cos_a - y * sin_a\n",
    "        reshaped[t][:, 1] = x * sin_a + y * cos_a\n",
    "\n",
    "    return reshaped.reshape(seq.shape)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 4) Time warping by interpolation\n",
    "# --------------------------------------------------\n",
    "def augment_time_warp(seq, speed_range=(0.9, 1.1)):\n",
    "    T = seq.shape[0]\n",
    "    speed = np.random.uniform(*speed_range)\n",
    "\n",
    "    # New number of frames\n",
    "    new_T = int(T * speed)\n",
    "    new_T = max(5, new_T)\n",
    "\n",
    "    indices = np.linspace(0, T - 1, new_T)\n",
    "    warped = np.zeros((new_T, seq.shape[1]))\n",
    "\n",
    "    for i, idx in enumerate(indices):\n",
    "        warped[i] = seq[int(idx)]\n",
    "        \n",
    "    # Resize back to original length\n",
    "    indices_fixed = np.linspace(0, new_T - 1, T)\n",
    "    fixed = np.zeros((T, seq.shape[1]))\n",
    "    for i, idx in enumerate(indices_fixed):\n",
    "        fixed[i] = warped[int(idx)]\n",
    "\n",
    "    return fixed\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 5) Random frame drop (mild)\n",
    "# --------------------------------------------------\n",
    "def augment_frame_drop(seq, drop_rate=0.05):\n",
    "    seq_aug = seq.copy()\n",
    "    T = seq.shape[0]\n",
    "\n",
    "    num_drop = int(T * drop_rate)\n",
    "    drop_idx = np.random.choice(T, num_drop, replace=False)\n",
    "\n",
    "    for idx in drop_idx:\n",
    "        seq_aug[idx] = seq_aug[idx - 1] if idx > 0 else seq_aug[idx]\n",
    "\n",
    "    return seq_aug\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# MASTER FUNCTION: Randomly apply augmentations\n",
    "# --------------------------------------------------\n",
    "def augment_sequence(seq):\n",
    "    if np.random.rand() < 0.5:\n",
    "        seq = augment_jitter(seq)\n",
    "\n",
    "    if np.random.rand() < 0.3:\n",
    "        seq = augment_scaling(seq)\n",
    "\n",
    "    if np.random.rand() < 0.3:\n",
    "        seq = augment_rotation(seq)\n",
    "\n",
    "    if np.random.rand() < 0.4:\n",
    "        seq = augment_time_warp(seq)\n",
    "\n",
    "    if np.random.rand() < 0.3:\n",
    "        seq = augment_frame_drop(seq)\n",
    "\n",
    "    return seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77a86fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pad_videos_list(videos, max_frames):\n",
    "#     \"\"\"\n",
    "#     Pad or truncate a list of videos to the same number of frames.\n",
    "\n",
    "#     videos: list of np.arrays, each (num_frames, num_points, dims) or (num_frames, feature_dim)\n",
    "#     max_frames: int, target number of frames\n",
    "#     # Returns: np.array of shape (num_videos, max_frames, ...)\n",
    "#     # \"\"\"\n",
    "    # padded_videos = []\n",
    "\n",
    "    # for video in videos:\n",
    "    #     video = np.asarray(video, dtype=np.float32)\n",
    "    #     num_frames = video.shape[0]\n",
    "    #     pad_amount = max_frames - num_frames\n",
    "\n",
    "    #     if pad_amount > 0:\n",
    "    #         # Create zeros to pad\n",
    "    #         if video.ndim == 3:  # (num_frames, num_points, dims)\n",
    "    #             pad_shape = (pad_amount, video.shape[1], video.shape[2])\n",
    "    #         elif video.ndim == 2:  # (num_frames, feature_dim)\n",
    "    #             pad_shape = (pad_amount, video.shape[1])\n",
    "    #         else:\n",
    "    #             raise ValueError(f\"Unsupported video shape: {video.shape}\")\n",
    "\n",
    "    #         video_padded = np.concatenate([video, np.zeros(pad_shape, dtype=np.float32)], axis=0)\n",
    "    #     else:\n",
    "    #         # Truncate if longer than max_frames\n",
    "    #         video_padded = video[:max_frames]\n",
    "\n",
    "    #     padded_videos.append(video_padded)\n",
    "\n",
    "    # # Stack into a single NumPy array\n",
    "    # return np.stack(padded_videos, axis=0)  # shape: (num_videos, max_frames, ...)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91277621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pose_input = pad_videos_list(pose_norm, 100)\n",
    "# lh_input   = pad_videos_list(lh_norm, 100)\n",
    "# rh_input   = pad_videos_list(rh_norm, 100)\n",
    "# face_input = pad_videos_list(face_norm, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "147f81f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos: 11980\n",
      "Shape of first video: (74, 438)\n"
     ]
    }
   ],
   "source": [
    "preprocessed_data = []\n",
    "\n",
    "for i in range(11980):\n",
    "    # concatenate features for video i\n",
    "    video_features = np.concatenate([\n",
    "        pose_videos[i], \n",
    "        face_videos[i],\n",
    "        lh_reconstructed[i],\n",
    "        rh_reconstructed[i],\n",
    "        \n",
    "    ], axis=1)   # combine feature columns\n",
    "\n",
    "    preprocessed_data.append(video_features)\n",
    "\n",
    "print(\"Number of videos:\", len(preprocessed_data))\n",
    "print(\"Shape of first video:\", preprocessed_data[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d9c334ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of augmented videos: 11980\n",
      "Example video shape: (74, 438)\n"
     ]
    }
   ],
   "source": [
    "augmented_list = []\n",
    "\n",
    "for video in preprocessed_data:\n",
    "    aug_video = augment_sequence(video)\n",
    "    augmented_list.append(aug_video)\n",
    "\n",
    "print(\"Number of augmented videos:\", len(augmented_list))\n",
    "print(\"Example video shape:\", augmented_list[0].shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
