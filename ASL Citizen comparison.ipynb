{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "37c7a2f2-240a-429d-989b-ceab8107b4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= UNIQUE GLOSSES =========\n",
      "ASL Citizen unique: 903\n",
      "WLASL unique:       533\n",
      "MSASL unique:       129\n",
      "TOTAL distinct glosses (union of all 3): 3068\n",
      "=================================\n",
      "\n",
      "========= FULL OVERLAP SUMMARY =========\n",
      "Unique glosses per dataset:\n",
      "  ASL only:           903\n",
      "  WLASL only:         533\n",
      "  MSASL only:         129\n",
      "\n",
      "Glosses shared by exactly 2 datasets:\n",
      "  ASL & WLASL only:   643\n",
      "  ASL & MSASL only:   36\n",
      "  WLASL & MSASL only: 105\n",
      "\n",
      "Glosses common to ALL THREE datasets: 719\n",
      "\n",
      "TOTAL distinct glosses (calculated): 3068\n",
      "TOTAL distinct glosses (union):      3068\n",
      "========================================\n",
      "\n",
      "MERGED COUNT CSV SAVED → all_counts.csv\n",
      "Total merged glosses: 3067\n",
      "         count_ASL  count_WLASL  count_MSASL  total_count\n",
      "bird             1           10           31           42\n",
      "fish             1           10           30           41\n",
      "eat              1            7           33           41\n",
      "teacher          1            8           31           40\n",
      "orange           1           10           29           40\n",
      "black            1           10           29           40\n",
      "school           1            9           30           40\n",
      "finish           1            9           30           40\n",
      "yes              1           12           27           40\n",
      "deaf             1           11           28           40\n",
      "like             1           10           28           39\n",
      "white            1           10           28           39\n",
      "drink            1           15           23           39\n",
      "man              1           12           26           39\n",
      "what             1           12           26           39\n",
      "water            1            9           28           38\n",
      "where            1            7           30           38\n",
      "blue             1            8           29           38\n",
      "friend           1            7           29           37\n",
      "yellow           1            8           28           37\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ===================== PATHS =====================\n",
    "asl_csv = \"asl_citizen_gloss_counts.csv\"\n",
    "wlasl_folder = \"landmarks_mapped\"\n",
    "msasl_folder = \"MSASL_Keypoints\"\n",
    "output_csv = \"all_counts.csv\"\n",
    "\n",
    "# ===================== NORMALIZE (Unified) =====================\n",
    "def normalize_gloss(name):\n",
    "    \"\"\"\n",
    "    Normalize a gloss name by:\n",
    "    1) Lowercasing\n",
    "    2) Taking only part before the first underscore\n",
    "    3) Removing trailing numbers\n",
    "    \"\"\"\n",
    "    name = str(name).lower()\n",
    "    name = name.split('_')[0]          # part before first underscore\n",
    "    name = re.sub(r'\\d+$', '', name)   # remove trailing digits\n",
    "    return name\n",
    "\n",
    "# ===================== COLLECT GLOSSES FROM FOLDERS =====================\n",
    "def collect_glosses(folder):\n",
    "    \"\"\"\n",
    "    Return a set of unique normalized glosses from .npy files.\n",
    "    \"\"\"\n",
    "    glosses = set()\n",
    "    for root, _, files in os.walk(folder):\n",
    "        for f in files:\n",
    "            if f.endswith(\".npy\"):\n",
    "                base = os.path.splitext(f)[0]\n",
    "                glosses.add(normalize_gloss(base))\n",
    "    return glosses\n",
    "\n",
    "# ===================== COUNT FILES PER GLOSS =====================\n",
    "def count_folder(folder):\n",
    "    counts = {}\n",
    "    for root, _, files in os.walk(folder):\n",
    "        for f in files:\n",
    "            if f.endswith(\".npy\"):\n",
    "                gloss = normalize_gloss(os.path.splitext(f)[0])\n",
    "                if gloss:\n",
    "                    counts[gloss] = counts.get(gloss, 0) + 1\n",
    "    return pd.Series(counts)\n",
    "\n",
    "# ===================== LOAD ASL CITIZEN =====================\n",
    "asl_df = pd.read_csv(asl_csv)\n",
    "asl_df[\"clean\"] = asl_df[\"gloss\"].apply(normalize_gloss)\n",
    "asl_counts = asl_df[\"clean\"].value_counts().rename(\"count_ASL\")\n",
    "asl_glosses = set(asl_df[\"clean\"])\n",
    "\n",
    "# ===================== LOAD WLASL & MSASL =====================\n",
    "wlasl_glosses = collect_glosses(wlasl_folder)\n",
    "msasl_glosses = collect_glosses(msasl_folder)\n",
    "\n",
    "wlasl_counts = count_folder(wlasl_folder).rename(\"count_WLASL\")\n",
    "msasl_counts = count_folder(msasl_folder).rename(\"count_MSASL\")\n",
    "\n",
    "# ===================== UNIQUE SET COMPARISONS =====================\n",
    "asl_unique = asl_glosses - wlasl_glosses - msasl_glosses\n",
    "wlasl_unique = wlasl_glosses - asl_glosses - msasl_glosses\n",
    "msasl_unique = msasl_glosses - asl_glosses - wlasl_glosses\n",
    "\n",
    "# Total distinct glosses across all datasets\n",
    "all_unique_glosses = asl_glosses | wlasl_glosses | msasl_glosses\n",
    "\n",
    "print(\"\\n========= UNIQUE GLOSSES =========\")\n",
    "print(f\"ASL Citizen unique: {len(asl_unique)}\")\n",
    "print(f\"WLASL unique:       {len(wlasl_unique)}\")\n",
    "print(f\"MSASL unique:       {len(msasl_unique)}\")\n",
    "print(f\"TOTAL distinct glosses (union of all 3): {len(all_unique_glosses)}\")\n",
    "print(\"=================================\\n\")\n",
    "\n",
    "# ===================== OVERLAP BREAKDOWN =====================\n",
    "\n",
    "# Glosses in exactly TWO datasets (but not the third)\n",
    "asl_wlasl_only = (asl_glosses & wlasl_glosses) - msasl_glosses\n",
    "asl_msasl_only = (asl_glosses & msasl_glosses) - wlasl_glosses\n",
    "wlasl_msasl_only = (wlasl_glosses & msasl_glosses) - asl_glosses\n",
    "\n",
    "# Glosses common to ALL THREE datasets\n",
    "common_all_three = asl_glosses & wlasl_glosses & msasl_glosses\n",
    "\n",
    "# Neat print of all categories\n",
    "print(\"========= FULL OVERLAP SUMMARY =========\")\n",
    "print(f\"Unique glosses per dataset:\")\n",
    "print(f\"  ASL only:           {len(asl_unique)}\")\n",
    "print(f\"  WLASL only:         {len(wlasl_unique)}\")\n",
    "print(f\"  MSASL only:         {len(msasl_unique)}\\n\")\n",
    "\n",
    "print(f\"Glosses shared by exactly 2 datasets:\")\n",
    "print(f\"  ASL & WLASL only:   {len(asl_wlasl_only)}\")\n",
    "print(f\"  ASL & MSASL only:   {len(asl_msasl_only)}\")\n",
    "print(f\"  WLASL & MSASL only: {len(wlasl_msasl_only)}\\n\")\n",
    "\n",
    "print(f\"Glosses common to ALL THREE datasets: {len(common_all_three)}\\n\")\n",
    "\n",
    "# Verify totals\n",
    "total_calculated = (\n",
    "    len(asl_unique) +\n",
    "    len(wlasl_unique) +\n",
    "    len(msasl_unique) +\n",
    "    len(asl_wlasl_only) +\n",
    "    len(asl_msasl_only) +\n",
    "    len(wlasl_msasl_only) +\n",
    "    len(common_all_three)\n",
    ")\n",
    "print(f\"TOTAL distinct glosses (calculated): {total_calculated}\")\n",
    "print(f\"TOTAL distinct glosses (union):      {len(all_unique_glosses)}\")\n",
    "print(\"========================================\\n\")\n",
    "\n",
    "# ===================== MERGE COUNTS =====================\n",
    "df = pd.concat([asl_counts, wlasl_counts, msasl_counts], axis=1).fillna(0).astype(int)\n",
    "df[\"total_count\"] = df.sum(axis=1)\n",
    "df = df.sort_values(\"total_count\", ascending=False)\n",
    "\n",
    "df.to_csv(output_csv)\n",
    "print(f\"MERGED COUNT CSV SAVED → {output_csv}\")\n",
    "print(f\"Total merged glosses: {len(df)}\")\n",
    "print(df.head(20))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (venv310)",
   "language": "python",
   "name": "venv310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
