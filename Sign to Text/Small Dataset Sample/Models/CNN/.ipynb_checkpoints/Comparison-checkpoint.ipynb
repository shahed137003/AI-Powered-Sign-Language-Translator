{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c57eb8-3a72-474e-9992-9a40b3afe941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import os\n",
    "\n",
    "# ==============================\n",
    "# CONFIG (same as your original)\n",
    "# ==============================\n",
    "DATA_DIR = r\"E:\\ASL_Citizen\\NEW\\Top_Classes_Landmarks_Preprocessed\"\n",
    "TARGET_FRAMES = 157\n",
    "FEATURE_DIM = 438\n",
    "BATCH_SIZE = 16\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "MODEL_PATHS = {\n",
    "    \"Hands Only + Sliding\": \"CNN_hands_only_sliding_mask_best_model.pth\",\n",
    "    \"All Features + Sliding\": \"CNN_with_sliding&mask_best_model.pth\",\n",
    "    \"All Features w/o Sliding\": \"CNN_without_sliding&mask_best_model.pth\",\n",
    "    \"Hands + Face + Sliding\": \"CNN_hands_face_sliding_mask_best_model.pth\",\n",
    "    \"Hands + Pose + Sliding\": \"CNN_hands_pose_sliding_mask_best_model.pth\"\n",
    "}\n",
    "\n",
    "# ==============================\n",
    "# DATASET\n",
    "# ==============================\n",
    "class LandmarkDataset(Dataset):\n",
    "    def __init__(self, files, labels):\n",
    "        self.files = files\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = np.load(self.files[idx]).astype(np.float32)\n",
    "        x = torch.tensor(x).permute(1,0)  # shape: (features, frames)\n",
    "        y = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return x, y\n",
    "\n",
    "# ==============================\n",
    "# LOAD FILES & LABELS\n",
    "# ==============================\n",
    "files, labels = [], []\n",
    "\n",
    "for f in os.listdir(DATA_DIR):\n",
    "    if f.endswith(\".npy\") and \"_mask\" not in f:\n",
    "        files.append(os.path.join(DATA_DIR, f))\n",
    "        gloss = f.rsplit(\"_\", 1)[0].split(\"_\")[0]\n",
    "        labels.append(gloss)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(labels)\n",
    "\n",
    "# Filter classes with <2 samples\n",
    "label_counts = Counter(y_encoded)\n",
    "valid_idx = [i for i, y in enumerate(y_encoded) if label_counts[y] >= 2]\n",
    "\n",
    "files = [files[i] for i in valid_idx]\n",
    "y_encoded = y_encoded[valid_idx]\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y_encoded)\n",
    "num_classes = len(le.classes_)\n",
    "\n",
    "# Train/Val/Test split (same as original)\n",
    "from sklearn.model_selection import train_test_split\n",
    "files_train, files_tmp, y_train, y_tmp = train_test_split(\n",
    "    files, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42\n",
    ")\n",
    "files_val, files_test, y_val, y_test = train_test_split(\n",
    "    files_tmp, y_tmp, test_size=0.5, stratify=y_tmp, random_state=42\n",
    ")\n",
    "\n",
    "test_dataset = LandmarkDataset(files_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# ==============================\n",
    "# MODEL\n",
    "# ==============================\n",
    "class CNN1D(nn.Module):\n",
    "    def __init__(self, input_features, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(input_features, 256, 3, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "\n",
    "            nn.Conv1d(256, 128, 3, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.05),\n",
    "\n",
    "            nn.Conv1d(128, 64, 3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveMaxPool1d(1)\n",
    "        )\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.squeeze(-1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# ==============================\n",
    "# EVALUATION FUNCTION\n",
    "# ==============================\n",
    "def evaluate_model(model_path):\n",
    "    model = CNN1D(FEATURE_DIM, num_classes).to(DEVICE)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
    "    model.eval()\n",
    "\n",
    "    all_preds, all_labels, all_probs = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            outputs = model(x)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            preds = outputs.argmax(1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    per_class_acc = []\n",
    "    for i in range(num_classes):\n",
    "        idxs = np.where(np.array(all_labels) == i)[0]\n",
    "        class_acc = (np.array(all_preds)[idxs] == np.array(all_labels)[idxs]).mean() if len(idxs)>0 else 0\n",
    "        per_class_acc.append(class_acc)\n",
    "\n",
    "    return acc, per_class_acc, np.array(all_probs)\n",
    "\n",
    "# ==============================\n",
    "# EVALUATE ALL MODELS\n",
    "# ==============================\n",
    "results = {}\n",
    "for name, path in MODEL_PATHS.items():\n",
    "    acc, per_class_acc, probs = evaluate_model(path)\n",
    "    results[name] = {\"accuracy\": acc, \"per_class_acc\": per_class_acc, \"probs\": probs}\n",
    "    print(f\"{name} Test Accuracy: {acc:.4f}\")\n",
    "\n",
    "# ==============================\n",
    "# VISUALIZATIONS\n",
    "# ==============================\n",
    "\n",
    "# 1️⃣ Overall Accuracy Comparison\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(results.keys(), [r[\"accuracy\"] for r in results.values()], color='skyblue')\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.title(\"Overall Test Accuracy Comparison\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylim(0,1)\n",
    "plt.show()\n",
    "\n",
    "# 2️⃣ Per-Class Accuracy Heatmap\n",
    "plt.figure(figsize=(12,6))\n",
    "per_class_matrix = np.array([r[\"per_class_acc\"] for r in results.values()])\n",
    "sns.heatmap(per_class_matrix, annot=True, fmt=\".2f\", cmap='YlGnBu', xticklabels=[f\"C{i}\" for i in range(num_classes)], yticklabels=results.keys())\n",
    "plt.xlabel(\"Class Index\")\n",
    "plt.ylabel(\"Model\")\n",
    "plt.title(\"Per-Class Accuracy Comparison\")\n",
    "plt.show()\n",
    "\n",
    "# 3️⃣ Prediction Confidence Distribution (Top-1 probs)\n",
    "plt.figure(figsize=(12,6))\n",
    "for name, r in results.items():\n",
    "    top1_probs = r[\"probs\"].max(axis=1)\n",
    "    sns.kdeplot(top1_probs, label=name, fill=True)\n",
    "plt.xlabel(\"Prediction Confidence (Top-1)\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Prediction Confidence Distribution\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (venv310)",
   "language": "python",
   "name": "venv310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
