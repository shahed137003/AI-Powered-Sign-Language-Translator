{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ef08eda-7c76-45d7-9e40-759a191af836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E001 | TL 4.526 TA 0.076 | VL 4.088 VA 0.125\n",
      "E002 | TL 3.720 TA 0.158 | VL 3.395 VA 0.226\n",
      "E003 | TL 3.185 TA 0.289 | VL 2.968 VA 0.349\n",
      "E004 | TL 2.789 TA 0.403 | VL 2.689 VA 0.421\n",
      "E005 | TL 2.495 TA 0.504 | VL 2.489 VA 0.491\n",
      "E006 | TL 2.260 TA 0.587 | VL 2.498 VA 0.498\n",
      "E007 | TL 2.057 TA 0.651 | VL 2.187 VA 0.615\n",
      "E008 | TL 1.940 TA 0.699 | VL 2.067 VA 0.652\n",
      "E009 | TL 1.824 TA 0.731 | VL 2.121 VA 0.616\n",
      "E010 | TL 1.717 TA 0.772 | VL 1.963 VA 0.700\n",
      "E011 | TL 1.631 TA 0.799 | VL 1.887 VA 0.695\n",
      "E012 | TL 1.551 TA 0.827 | VL 1.833 VA 0.733\n",
      "E013 | TL 1.484 TA 0.850 | VL 1.793 VA 0.743\n",
      "E014 | TL 1.438 TA 0.867 | VL 1.795 VA 0.765\n",
      "E015 | TL 1.384 TA 0.889 | VL 1.773 VA 0.743\n",
      "E016 | TL 1.347 TA 0.896 | VL 1.695 VA 0.762\n",
      "E017 | TL 1.304 TA 0.913 | VL 1.726 VA 0.757\n",
      "E018 | TL 1.268 TA 0.923 | VL 1.671 VA 0.789\n",
      "E019 | TL 1.244 TA 0.929 | VL 1.676 VA 0.776\n",
      "E020 | TL 1.213 TA 0.940 | VL 1.662 VA 0.788\n",
      "E021 | TL 1.193 TA 0.939 | VL 1.631 VA 0.788\n",
      "E022 | TL 1.158 TA 0.956 | VL 1.598 VA 0.798\n",
      "E023 | TL 1.143 TA 0.959 | VL 1.636 VA 0.772\n",
      "E024 | TL 1.119 TA 0.966 | VL 1.601 VA 0.791\n",
      "E025 | TL 1.099 TA 0.968 | VL 1.627 VA 0.789\n",
      "E026 | TL 1.088 TA 0.970 | VL 1.638 VA 0.800\n",
      "E027 | TL 1.076 TA 0.977 | VL 1.571 VA 0.798\n",
      "E028 | TL 1.056 TA 0.981 | VL 1.532 VA 0.801\n",
      "E029 | TL 1.042 TA 0.982 | VL 1.526 VA 0.829\n",
      "E030 | TL 1.034 TA 0.985 | VL 1.575 VA 0.808\n",
      "E031 | TL 1.023 TA 0.985 | VL 1.560 VA 0.812\n",
      "E032 | TL 1.013 TA 0.990 | VL 1.516 VA 0.820\n",
      "E033 | TL 1.000 TA 0.990 | VL 1.490 VA 0.830\n",
      "E034 | TL 0.993 TA 0.991 | VL 1.520 VA 0.818\n",
      "E035 | TL 0.983 TA 0.991 | VL 1.511 VA 0.824\n",
      "E036 | TL 0.975 TA 0.992 | VL 1.544 VA 0.820\n",
      "E037 | TL 0.971 TA 0.994 | VL 1.532 VA 0.812\n",
      "E038 | TL 0.962 TA 0.995 | VL 1.466 VA 0.829\n",
      "E039 | TL 0.953 TA 0.996 | VL 1.497 VA 0.818\n",
      "E040 | TL 0.944 TA 0.998 | VL 1.457 VA 0.842\n",
      "E041 | TL 0.943 TA 0.996 | VL 1.499 VA 0.825\n",
      "E042 | TL 0.939 TA 0.997 | VL 1.454 VA 0.839\n",
      "E043 | TL 0.930 TA 0.998 | VL 1.463 VA 0.825\n",
      "E044 | TL 0.926 TA 0.998 | VL 1.466 VA 0.830\n",
      "E045 | TL 0.921 TA 0.999 | VL 1.463 VA 0.836\n",
      "E046 | TL 0.917 TA 0.998 | VL 1.464 VA 0.842\n",
      "E047 | TL 0.912 TA 0.999 | VL 1.450 VA 0.841\n",
      "E048 | TL 0.910 TA 0.998 | VL 1.450 VA 0.844\n",
      "E049 | TL 0.906 TA 0.998 | VL 1.439 VA 0.844\n",
      "E050 | TL 0.903 TA 0.999 | VL 1.438 VA 0.841\n",
      "E051 | TL 0.898 TA 0.999 | VL 1.469 VA 0.842\n",
      "E052 | TL 0.894 TA 1.000 | VL 1.453 VA 0.848\n",
      "E053 | TL 0.894 TA 0.999 | VL 1.441 VA 0.848\n",
      "E054 | TL 0.889 TA 1.000 | VL 1.437 VA 0.841\n",
      "E055 | TL 0.888 TA 1.000 | VL 1.444 VA 0.836\n",
      "E056 | TL 0.885 TA 1.000 | VL 1.425 VA 0.848\n",
      "E057 | TL 0.883 TA 1.000 | VL 1.427 VA 0.849\n",
      "E058 | TL 0.880 TA 1.000 | VL 1.418 VA 0.854\n",
      "E059 | TL 0.877 TA 1.000 | VL 1.424 VA 0.839\n",
      "E060 | TL 0.877 TA 1.000 | VL 1.423 VA 0.854\n",
      "E061 | TL 0.875 TA 1.000 | VL 1.424 VA 0.853\n",
      "E062 | TL 0.872 TA 1.000 | VL 1.423 VA 0.841\n",
      "E063 | TL 0.871 TA 1.000 | VL 1.412 VA 0.851\n",
      "E064 | TL 0.871 TA 1.000 | VL 1.405 VA 0.858\n",
      "E065 | TL 0.869 TA 1.000 | VL 1.411 VA 0.856\n",
      "E066 | TL 0.867 TA 1.000 | VL 1.415 VA 0.854\n",
      "E067 | TL 0.866 TA 1.000 | VL 1.401 VA 0.854\n",
      "E068 | TL 0.865 TA 1.000 | VL 1.404 VA 0.861\n",
      "E069 | TL 0.864 TA 1.000 | VL 1.401 VA 0.851\n",
      "E070 | TL 0.863 TA 1.000 | VL 1.394 VA 0.854\n",
      "E071 | TL 0.861 TA 1.000 | VL 1.395 VA 0.860\n",
      "E072 | TL 0.860 TA 1.000 | VL 1.403 VA 0.854\n",
      "E073 | TL 0.860 TA 1.000 | VL 1.404 VA 0.851\n",
      "E074 | TL 0.859 TA 1.000 | VL 1.397 VA 0.856\n",
      "E075 | TL 0.859 TA 1.000 | VL 1.398 VA 0.856\n",
      "E076 | TL 0.858 TA 1.000 | VL 1.397 VA 0.856\n",
      "E077 | TL 0.858 TA 1.000 | VL 1.400 VA 0.863\n",
      "E078 | TL 0.857 TA 1.000 | VL 1.407 VA 0.858\n",
      "E079 | TL 0.856 TA 1.000 | VL 1.399 VA 0.858\n",
      "E080 | TL 0.856 TA 1.000 | VL 1.406 VA 0.858\n",
      "E081 | TL 0.856 TA 1.000 | VL 1.402 VA 0.854\n",
      "E082 | TL 0.855 TA 1.000 | VL 1.406 VA 0.860\n",
      "E083 | TL 0.854 TA 1.000 | VL 1.404 VA 0.865\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CPU-SAFE TCN FOR ASL LANDMARKS (TRAINING)\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG\n",
    "# ============================================================\n",
    "\n",
    "DATA_DIR = Path(r\"E:\\ASL_Citizen\\NEW\\Top_Classes_Landmarks_Preprocessed\")\n",
    "DEVICE = \"cpu\"\n",
    "\n",
    "TARGET_FRAMES = 157\n",
    "FEATURE_DIM = 438\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 90\n",
    "LR = 3e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "\n",
    "PATIENCE = 12\n",
    "GRAD_CLIP = 1.0\n",
    "LABEL_SMOOTH = 0.1\n",
    "\n",
    "MODEL_SAVE_PATH = DATA_DIR / \"tcn_best_cpu_3rdcode.pth\"\n",
    "LABEL_ENCODER_PATH = DATA_DIR / \"label_encoder_3rdcode.npy\"\n",
    "\n",
    "# ============================================================\n",
    "# LOAD FILES\n",
    "# ============================================================\n",
    "\n",
    "files, masks, labels = [], [], []\n",
    "\n",
    "for f in DATA_DIR.glob(\"*.npy\"):\n",
    "    if f.name.endswith(\"_mask.npy\"):\n",
    "        continue\n",
    "\n",
    "    mask_f = f.with_name(f.stem + \"_mask.npy\")\n",
    "    if not mask_f.exists():\n",
    "        continue\n",
    "\n",
    "    arr = np.load(f)\n",
    "    if arr.shape != (TARGET_FRAMES, FEATURE_DIM):\n",
    "        continue\n",
    "\n",
    "    files.append(str(f))\n",
    "    masks.append(str(mask_f))\n",
    "    labels.append(f.stem.split(\"_\")[0])\n",
    "\n",
    "# Filter rare classes\n",
    "cnt = Counter(labels)\n",
    "keep = [i for i, y in enumerate(labels) if cnt[y] >= 2]\n",
    "\n",
    "files = [files[i] for i in keep]\n",
    "masks = [masks[i] for i in keep]\n",
    "labels = [labels[i] for i in keep]\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(labels)\n",
    "np.save(LABEL_ENCODER_PATH, le.classes_)\n",
    "num_classes = len(le.classes_)\n",
    "\n",
    "# ============================================================\n",
    "# SPLITS\n",
    "# ============================================================\n",
    "\n",
    "X_tr, X_tmp, y_tr, y_tmp, m_tr, m_tmp = train_test_split(\n",
    "    files, y, masks, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "X_val, X_te, y_val, y_te, m_val, m_te = train_test_split(\n",
    "    X_tmp, y_tmp, m_tmp, test_size=0.5, stratify=y_tmp, random_state=42\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# DATASET\n",
    "# ============================================================\n",
    "\n",
    "class ASLDataset(Dataset):\n",
    "    def __init__(self, files, masks, labels):\n",
    "        self.files = files\n",
    "        self.masks = masks\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.from_numpy(np.load(self.files[idx])).float().transpose(0, 1)\n",
    "        m = torch.from_numpy(np.load(self.masks[idx])).float()\n",
    "        y = torch.tensor(self.labels[idx])\n",
    "        return x, m, y\n",
    "\n",
    "train_loader = DataLoader(ASLDataset(X_tr, m_tr, y_tr), BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(ASLDataset(X_val, m_val, y_val), BATCH_SIZE)\n",
    "test_loader  = DataLoader(ASLDataset(X_te, m_te, y_te), BATCH_SIZE)\n",
    "\n",
    "# ============================================================\n",
    "# MODEL (UNCHANGED)\n",
    "# ============================================================\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, ic, oc, d):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(ic, oc, 3, padding=d, dilation=d),\n",
    "            nn.BatchNorm1d(oc),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(oc, oc, 3, padding=d, dilation=d),\n",
    "            nn.BatchNorm1d(oc),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.res = nn.Conv1d(ic, oc, 1) if ic != oc else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.net(x)\n",
    "        y = y[..., :x.size(2)]\n",
    "        return y + self.res(x)\n",
    "\n",
    "class TCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        chans = [192, 192, 192, 192]\n",
    "        layers = []\n",
    "        for i, c in enumerate(chans):\n",
    "            layers.append(TemporalBlock(\n",
    "                FEATURE_DIM if i == 0 else chans[i-1],\n",
    "                c, 2 ** i\n",
    "            ))\n",
    "        self.tcn = nn.Sequential(*layers)\n",
    "        self.fc = nn.Linear(chans[-1], num_classes)\n",
    "\n",
    "    def masked_pool(self, x, m):\n",
    "        m = m.unsqueeze(1)\n",
    "        return (x * m).sum(2) / (m.sum(2) + 1e-6)\n",
    "\n",
    "    def forward(self, x, m):\n",
    "        x = self.tcn(x)\n",
    "        x = self.masked_pool(x, m)\n",
    "        return self.fc(x)\n",
    "\n",
    "model = TCN().to(DEVICE)\n",
    "\n",
    "# ============================================================\n",
    "# LOSS\n",
    "# ============================================================\n",
    "\n",
    "weights = compute_class_weight(\"balanced\", classes=np.unique(y_tr), y=y_tr)\n",
    "weights = torch.tensor(weights).float()\n",
    "\n",
    "class SmoothCE(nn.Module):\n",
    "    def __init__(self, eps=0.1):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, logits, target):\n",
    "        n = logits.size(1)\n",
    "        logp = torch.log_softmax(logits, 1)\n",
    "        y = torch.zeros_like(logp).fill_(self.eps / n)\n",
    "        y.scatter_(1, target.unsqueeze(1), 1 - self.eps)\n",
    "        return -(y * logp).sum(1).mean()\n",
    "\n",
    "criterion = SmoothCE(LABEL_SMOOTH)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), LR, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = CosineAnnealingLR(optimizer, EPOCHS)\n",
    "\n",
    "# ============================================================\n",
    "# TRAIN\n",
    "# ============================================================\n",
    "\n",
    "def run(loader, train=True):\n",
    "    model.train() if train else model.eval()\n",
    "    loss_sum, correct, total = 0, 0, 0\n",
    "    with torch.set_grad_enabled(train):\n",
    "        for x, m, y in loader:\n",
    "            x, m, y = x.to(DEVICE), m.to(DEVICE), y.to(DEVICE)\n",
    "            out = model(x, m)\n",
    "            loss = criterion(out, y)\n",
    "            if train:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
    "                optimizer.step()\n",
    "            loss_sum += loss.item() * y.size(0)\n",
    "            correct += (out.argmax(1) == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    return loss_sum / total, correct / total\n",
    "\n",
    "best, patience = -1e9, 0\n",
    "\n",
    "for e in range(EPOCHS):\n",
    "    tr_l, tr_a = run(train_loader, True)\n",
    "    va_l, va_a = run(val_loader, False)\n",
    "    scheduler.step()\n",
    "    metric = va_a - va_l\n",
    "\n",
    "    print(f\"E{e+1:03d} | TL {tr_l:.3f} TA {tr_a:.3f} | VL {va_l:.3f} VA {va_a:.3f}\")\n",
    "\n",
    "    if metric > best:\n",
    "        best = metric\n",
    "        patience = 0\n",
    "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "    else:\n",
    "        patience += 1\n",
    "        if patience >= PATIENCE:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42a520f7-c978-44f3-99a9-5aeaa402b87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "TEST LOSS: 1.3105\n",
      "TEST ACC : 0.8957\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# TEST EVALUATION\n",
    "# ============================================================\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(torch.load(MODEL_SAVE_PATH, map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "test_loss, test_acc = run(test_loader, train=False)\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(f\"TEST LOSS: {test_loss:.4f}\")\n",
    "print(f\"TEST ACC : {test_acc:.4f}\")\n",
    "print(\"==============================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "14b2b0b9-99b6-47b2-a4ad-dd5937756b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "TEST LOSS   : 1.3105\n",
      "TOP-1 ACC   : 0.8957\n",
      "TOP-5 ACC   : 0.9726\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# TEST EVALUATION (Top-1, Top-5, Confusion Matrix)\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.load_state_dict(torch.load(MODEL_SAVE_PATH, map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "all_top5_correct = 0\n",
    "total = 0\n",
    "loss_sum = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, m, y in test_loader:\n",
    "        x, m, y = x.to(DEVICE), m.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "        logits = model(x, m)\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "\n",
    "        # Top-1\n",
    "        preds = probs.argmax(dim=1)\n",
    "\n",
    "        # Top-5\n",
    "        top5 = torch.topk(probs, k=5, dim=1).indices\n",
    "        top5_correct = top5.eq(y.view(-1, 1)).sum().item()\n",
    "\n",
    "        all_top5_correct += top5_correct\n",
    "        loss_sum += loss.item() * y.size(0)\n",
    "        total += y.size(0)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_targets.extend(y.cpu().numpy())\n",
    "\n",
    "test_loss = loss_sum / total\n",
    "top1_acc = np.mean(np.array(all_preds) == np.array(all_targets))\n",
    "top5_acc = all_top5_correct / total\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(f\"TEST LOSS   : {test_loss:.4f}\")\n",
    "print(f\"TOP-1 ACC   : {top1_acc:.4f}\")\n",
    "print(f\"TOP-5 ACC   : {top5_acc:.4f}\")\n",
    "print(\"==============================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6b21dcf6-585b-4c36-b16d-05a220497b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "EVALUATION METRICS\n",
      "==============================\n",
      "Accuracy        : 0.8957\n",
      "\n",
      "Macro Average (All classes equally weighted)\n",
      "Precision (Macro): 0.9171\n",
      "Recall (Macro)   : 0.8995\n",
      "F1 Score (Macro) : 0.8987\n",
      "\n",
      "Weighted Average (Accounts for imbalance)\n",
      "Precision (Weighted): 0.9104\n",
      "Recall (Weighted)   : 0.8957\n",
      "F1 Score (Weighted) : 0.8943\n",
      "\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(\"EVALUATION METRICS\")\n",
    "print(\"==============================\")\n",
    "\n",
    "# Overall Accuracy\n",
    "acc = accuracy_score(all_targets, all_preds)\n",
    "print(f\"Accuracy        : {acc:.4f}\")\n",
    "\n",
    "# Macro (treat all classes equally)\n",
    "precision_macro = precision_score(all_targets, all_preds, average='macro')\n",
    "recall_macro = recall_score(all_targets, all_preds, average='macro')\n",
    "f1_macro = f1_score(all_targets, all_preds, average='macro')\n",
    "\n",
    "print(\"\\nMacro Average (All classes equally weighted)\")\n",
    "print(f\"Precision (Macro): {precision_macro:.4f}\")\n",
    "print(f\"Recall (Macro)   : {recall_macro:.4f}\")\n",
    "print(f\"F1 Score (Macro) : {f1_macro:.4f}\")\n",
    "\n",
    "# Weighted (accounts for class imbalance)\n",
    "precision_weighted = precision_score(all_targets, all_preds, average='weighted')\n",
    "recall_weighted = recall_score(all_targets, all_preds, average='weighted')\n",
    "f1_weighted = f1_score(all_targets, all_preds, average='weighted')\n",
    "\n",
    "print(\"\\nWeighted Average (Accounts for imbalance)\")\n",
    "print(f\"Precision (Weighted): {precision_weighted:.4f}\")\n",
    "print(f\"Recall (Weighted)   : {recall_weighted:.4f}\")\n",
    "print(f\"F1 Score (Weighted) : {f1_weighted:.4f}\")\n",
    "\n",
    "print(\"\\n==============================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b65137cc-b1c5-4692-bed7-c42dd0a8f183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "        TEMPORAL CONVOLUTIONAL NETWORK\n",
      "==================================================\n",
      "\n",
      "Input:\n",
      "  Shape: (Batch, 438, 157)\n",
      "\n",
      "Temporal Blocks:\n",
      "\n",
      "  ┌─ Block 1\n",
      "  │  Conv1: 438 → 192 | k=3 | dilation=1\n",
      "  │  Conv2: 192 → 192 | k=3 | dilation=1\n",
      "  │  Residual: Conv1x1\n",
      "  └────────────────────────\n",
      "\n",
      "  ┌─ Block 2\n",
      "  │  Conv1: 192 → 192 | k=3 | dilation=2\n",
      "  │  Conv2: 192 → 192 | k=3 | dilation=2\n",
      "  │  Residual: Identity\n",
      "  └────────────────────────\n",
      "\n",
      "  ┌─ Block 3\n",
      "  │  Conv1: 192 → 192 | k=3 | dilation=4\n",
      "  │  Conv2: 192 → 192 | k=3 | dilation=4\n",
      "  │  Residual: Identity\n",
      "  └────────────────────────\n",
      "\n",
      "  ┌─ Block 4\n",
      "  │  Conv1: 192 → 192 | k=3 | dilation=8\n",
      "  │  Conv2: 192 → 192 | k=3 | dilation=8\n",
      "  │  Residual: Identity\n",
      "  └────────────────────────\n",
      "\n",
      "Masked Global Average Pooling\n",
      "  Output: (Batch, 192)\n",
      "\n",
      "Fully Connected:\n",
      "  Linear: 192 → 146\n",
      "\n",
      "--------------------------------------------------\n",
      "Total Parameters: 1,143,506\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_model_blocks(model):\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"        TEMPORAL CONVOLUTIONAL NETWORK\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    print(\"\\nInput:\")\n",
    "    print(f\"  Shape: (Batch, {FEATURE_DIM}, {TARGET_FRAMES})\")\n",
    "\n",
    "    print(\"\\nTemporal Blocks:\")\n",
    "    for i, block in enumerate(model.tcn):\n",
    "        conv1 = block.net[0]\n",
    "        conv2 = block.net[3]\n",
    "        print(f\"\\n  ┌─ Block {i+1}\")\n",
    "        print(f\"  │  Conv1: {conv1.in_channels} → {conv1.out_channels} | \"\n",
    "              f\"k=3 | dilation={conv1.dilation[0]}\")\n",
    "        print(f\"  │  Conv2: {conv2.in_channels} → {conv2.out_channels} | \"\n",
    "              f\"k=3 | dilation={conv2.dilation[0]}\")\n",
    "        print(f\"  │  Residual: {'Conv1x1' if isinstance(block.res, nn.Conv1d) else 'Identity'}\")\n",
    "        print(f\"  └────────────────────────\")\n",
    "\n",
    "    print(\"\\nMasked Global Average Pooling\")\n",
    "    print(f\"  Output: (Batch, 192)\")\n",
    "\n",
    "    print(\"\\nFully Connected:\")\n",
    "    print(f\"  Linear: 192 → {model.fc.out_features}\")\n",
    "\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(\"\\n\" + \"-\"*50)\n",
    "    print(f\"Total Parameters: {total_params:,}\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "print_model_blocks(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5029708-efc3-4490-8e38-e9ef0befab8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press R to start recording\n",
      "Press E to end recording and predict\n",
      "Press Q to quit\n",
      "Recording...\n",
      "Captured 179 frames\n",
      "\n",
      "Prediction: cry (0.945)\n",
      "Strategy used: sliding_window\n",
      "Recording...\n",
      "Captured 223 frames\n",
      "\n",
      "Prediction: candy (0.625)\n",
      "Strategy used: sliding_window\n",
      "Recording...\n",
      "Captured 106 frames\n",
      "\n",
      "Prediction: brown (0.866)\n",
      "Strategy used: edge_padding\n",
      "Recording...\n",
      "Captured 68 frames\n",
      "\n",
      "Prediction: brush (0.748)\n",
      "Strategy used: edge_padding\n",
      "Recording...\n",
      "Captured 67 frames\n",
      "\n",
      "Prediction: cat (0.564)\n",
      "Strategy used: edge_padding\n"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    # Paths\n",
    "    MSASL_RAW_DIR = Path(r\"E:\\ASL_Citizen\\NEW\\Top_Classes_Landmarks\")  # <-- only one dataset\n",
    "    WLASL_RAW_DIR = None  # or just ignore WLASL usage\n",
    "    OUTPUT_DIR = Path(r\"E:\\ASL_Citizen\\NEW\\Top_Classes_Landmarks_Preprocessed\")\n",
    "    SPLITS_DIR = Path(\"./data/Enhanced_Splits_157Frames\")\n",
    "    ANALYSIS_DIR = Path(\"./data/analysis_results\")\n",
    "    \n",
    "    # Create directories\n",
    "    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    SPLITS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    ANALYSIS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Based on your analysis\n",
    "    TARGET_FRAMES = 157                    # <-- changed\n",
    "    FEATURE_DIM = 438                     # same as before\n",
    "    MIN_SAMPLES_PER_WORD = 5              # same as before\n",
    "    \n",
    "    # Frame strategy parameters (from your analysis)\n",
    "    MAX_SINGLE_FRAMES = 140               # same\n",
    "    WINDOW_THRESHOLD = 161                # same\n",
    "    VERY_LONG_THRESHOLD = 201             # same\n",
    "    \n",
    "    # Geometry constants\n",
    "    POSE_SIZE = 132\n",
    "    HAND_SIZE = 63\n",
    "    FACE_SIZE = 180\n",
    "    POSE_LANDMARKS, POSE_VALS = 33, 4\n",
    "    HAND_LANDMARKS, HAND_VALS = 21, 3\n",
    "    FACE_LANDMARKS, FACE_VALS = 60, 3\n",
    "    LEG_IDXS = list(range(25, 33))\n",
    "    CRITICAL_POSE_IDXS = {0, 11, 12, 13, 14, 15, 16, 23, 24}\n",
    "    \n",
    "    # Preprocessing parameters\n",
    "    SMOOTH_POSE = True\n",
    "    SMOOTH_HANDS = True\n",
    "    SMOOTH_FACE = False\n",
    "    POSE_MIN_CUTOFF = 1.5\n",
    "    POSE_BETA = 0.4\n",
    "    HAND_MIN_CUTOFF = 2.0\n",
    "    HAND_BETA = 0.3\n",
    "    FACE_MIN_CUTOFF = 2.0\n",
    "    FACE_BETA = 0.4\n",
    "    D_CUTOFF = 1.0\n",
    "    FPS = 20.0\n",
    "    EPS = 1e-8\n",
    "\n",
    "config = Config()\n",
    "# ============================================================================\n",
    "# 1. ENHANCED GEOMETRY FUNCTIONS (Keep your original)\n",
    "# ============================================================================\n",
    "def in_unit_xy(x: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Mask where x,y are finite and within [0,1].\"\"\"\n",
    "    return (\n",
    "        np.isfinite(x) & np.isfinite(y) &\n",
    "        (x >= 0.0) & (x <= 1.0) &\n",
    "        (y >= 0.0) & (y <= 1.0)\n",
    "    )\n",
    "\n",
    "def reasonable_xy(x: np.ndarray, y: np.ndarray, lo: float = -0.25, hi: float = 1.25) -> np.ndarray:\n",
    "    \"\"\"Relaxed normalized check (helps during fast motion / partial crops).\"\"\"\n",
    "    return (\n",
    "        np.isfinite(x) & np.isfinite(y) &\n",
    "        (x >= lo) & (x <= hi) &\n",
    "        (y >= lo) & (y <= hi)\n",
    "    )\n",
    "\n",
    "def valid_points_xyz(arr: np.ndarray, eps: float = 1e-8) -> np.ndarray:\n",
    "    \"\"\"arr shape (...,3) -> mask over last axis: point is not all-zero.\"\"\"\n",
    "    return np.any(np.abs(arr) > eps, axis=-1)\n",
    "\n",
    "def is_valid_wrist(w: np.ndarray, eps: float = 1e-8) -> bool:\n",
    "    return bool(np.isfinite(w).all() and np.any(np.abs(w) > eps))\n",
    "\n",
    "def dist2(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    \"\"\"2D distance in XY.\"\"\"\n",
    "    return float(np.linalg.norm(a[:2] - b[:2]))\n",
    "# ============================================================================\n",
    "# 2. ENHANCED NORMALIZATION (Keep your original)\n",
    "# ============================================================================\n",
    "def compute_global_root(pose_xyz: np.ndarray, vis: np.ndarray, eps: float = 1e-8) -> np.ndarray:\n",
    "    def collect_mid(i1: int, i2: int):\n",
    "        m = (vis[:, i1] > 0.0) & (vis[:, i2] > 0.0)\n",
    "        m = m & valid_points_xyz(pose_xyz[:, i1, :], eps) & valid_points_xyz(pose_xyz[:, i2, :], eps)\n",
    "        if not np.any(m):\n",
    "            return None\n",
    "        return (pose_xyz[m, i1, :] + pose_xyz[m, i2, :]) / 2.0\n",
    "\n",
    "    mid_hip = collect_mid(23, 24)\n",
    "    if mid_hip is not None:\n",
    "        return mid_hip.mean(axis=0)\n",
    "\n",
    "    mid_sh = collect_mid(11, 12)\n",
    "    if mid_sh is not None:\n",
    "        return mid_sh.mean(axis=0)\n",
    "\n",
    "    m_nose = (vis[:, 0] > 0.0) & valid_points_xyz(pose_xyz[:, 0, :], eps)\n",
    "    if np.any(m_nose):\n",
    "        return pose_xyz[m_nose, 0, :].mean(axis=0)\n",
    "\n",
    "    m_all = (vis > 0.0) & valid_points_xyz(pose_xyz, eps)\n",
    "    if np.any(m_all):\n",
    "        return pose_xyz[m_all].mean(axis=0)\n",
    "\n",
    "    return np.zeros(3, dtype=np.float32)\n",
    "\n",
    "def compute_global_scale(pose_xyz: np.ndarray, vis: np.ndarray, root: np.ndarray, eps: float = 1e-6) -> float:\n",
    "    def collect_dist(i1: int, i2: int):\n",
    "        m = (vis[:, i1] > 0.0) & (vis[:, i2] > 0.0)\n",
    "        m = m & valid_points_xyz(pose_xyz[:, i1, :]) & valid_points_xyz(pose_xyz[:, i2, :])\n",
    "        if not np.any(m):\n",
    "            return None\n",
    "        d = np.linalg.norm(pose_xyz[m, i1, :] - pose_xyz[m, i2, :], axis=1)\n",
    "        d = d[d > eps]\n",
    "        return d if d.size > 0 else None\n",
    "\n",
    "    d_sh = collect_dist(11, 12)\n",
    "    if d_sh is not None:\n",
    "        return float(d_sh.mean())\n",
    "\n",
    "    d_hip = collect_dist(23, 24)\n",
    "    if d_hip is not None:\n",
    "        return float(d_hip.mean())\n",
    "\n",
    "    m_all = (vis > 0.0) & valid_points_xyz(pose_xyz)\n",
    "    if np.any(m_all):\n",
    "        d = np.linalg.norm(pose_xyz[m_all] - root[None, :], axis=1)\n",
    "        d = d[d > eps]\n",
    "        if d.size > 0:\n",
    "            return float(d.mean())\n",
    "\n",
    "    return 1.0\n",
    "# ============================================================================\n",
    "# 3. ENHANCED HAND FIXING (Keep your original)\n",
    "# ============================================================================\n",
    "def frame_valid_hand(hand_t: np.ndarray, min_pts: int = 8, eps: float = 1e-8) -> bool:\n",
    "    \"\"\"A frame counts as 'hand present' if it has >= min_pts non-zero landmarks.\"\"\"\n",
    "    nz = np.any(np.abs(hand_t) > eps, axis=1)\n",
    "    return int(nz.sum()) >= int(min_pts)\n",
    "\n",
    "def hand_centroid(hand_t: np.ndarray, eps: float = 1e-8):\n",
    "    m = np.any(np.abs(hand_t) > eps, axis=1)\n",
    "    if not np.any(m):\n",
    "        return None\n",
    "    return hand_t[m].mean(axis=0)\n",
    "\n",
    "def fix_swap_and_gate_hands(\n",
    "    lh: np.ndarray, rh: np.ndarray,\n",
    "    lw: np.ndarray, rw: np.ndarray,\n",
    "    min_pts: int = 8,\n",
    "    hand_wrist_max_dist: float = 1.1,\n",
    "    eps: float = 1e-8,\n",
    ") -> None:\n",
    "    T = lh.shape[0]\n",
    "    for t in range(T):\n",
    "        l_ok = frame_valid_hand(lh[t], min_pts=min_pts, eps=eps)\n",
    "        r_ok = frame_valid_hand(rh[t], min_pts=min_pts, eps=eps)\n",
    "\n",
    "        wl_ok = is_valid_wrist(lw[t], eps=eps)\n",
    "        wr_ok = is_valid_wrist(rw[t], eps=eps)\n",
    "\n",
    "        cL = hand_centroid(lh[t], eps=eps) if l_ok else None\n",
    "        cR = hand_centroid(rh[t], eps=eps) if r_ok else None\n",
    "\n",
    "        if l_ok and r_ok and wl_ok and wr_ok and (cL is not None) and (cR is not None):\n",
    "            d_ll = dist2(cL, lw[t])\n",
    "            d_lr = dist2(cL, rw[t])\n",
    "            d_rr = dist2(cR, rw[t])\n",
    "            d_rl = dist2(cR, lw[t])\n",
    "            if (d_lr + d_rl) + 1e-6 < (d_ll + d_rr):\n",
    "                lh[t], rh[t] = rh[t].copy(), lh[t].copy()\n",
    "                cL, cR = cR, cL\n",
    "\n",
    "        if wl_ok and l_ok and (cL is not None):\n",
    "            if dist2(cL, lw[t]) > hand_wrist_max_dist:\n",
    "                lh[t] = 0.0\n",
    "        if wr_ok and r_ok and (cR is not None):\n",
    "            if dist2(cR, rw[t]) > hand_wrist_max_dist:\n",
    "                rh[t] = 0.0\n",
    "\n",
    "def fill_hand_gaps_wrist_relative_tiered(\n",
    "    hand: np.ndarray,\n",
    "    wrist: np.ndarray,\n",
    "    small_gap: int = 6,\n",
    "    medium_gap: int = 15,\n",
    "    min_pts: int = 8,\n",
    "    rel_change_thresh: float = 0.7,\n",
    "    eps: float = 1e-8,\n",
    ") -> None:\n",
    "    T = hand.shape[0]\n",
    "    valid = np.array([frame_valid_hand(hand[t], min_pts=min_pts, eps=eps) for t in range(T)], dtype=bool)\n",
    "    idx = np.where(valid)[0]\n",
    "    if idx.size == 0:\n",
    "        return\n",
    "\n",
    "    def set_from_rel(t: int, rel: np.ndarray):\n",
    "        if is_valid_wrist(wrist[t], eps=eps):\n",
    "            hand[t] = rel + wrist[t]\n",
    "\n",
    "    for a, b in zip(idx[:-1], idx[1:]):\n",
    "        gap = int(b - a - 1)\n",
    "        if gap <= 0:\n",
    "            continue\n",
    "        if gap > medium_gap:\n",
    "            continue\n",
    "\n",
    "        if not (is_valid_wrist(wrist[a], eps=eps) and is_valid_wrist(wrist[b], eps=eps)):\n",
    "            if gap <= small_gap:\n",
    "                for t in range(a + 1, b):\n",
    "                    hand[t] = hand[a]\n",
    "            continue\n",
    "\n",
    "        rel_a = hand[a] - wrist[a]\n",
    "        rel_b = hand[b] - wrist[b]\n",
    "\n",
    "        if gap > small_gap:\n",
    "            for t in range(a + 1, b):\n",
    "                set_from_rel(t, rel_a)\n",
    "            continue\n",
    "\n",
    "        delta = np.linalg.norm(rel_a - rel_b, axis=1)\n",
    "        delta = delta[np.isfinite(delta)]\n",
    "        rel_delta = float(np.median(delta)) if delta.size else 999.0\n",
    "\n",
    "        if rel_delta <= rel_change_thresh:\n",
    "            for t in range(a + 1, b):\n",
    "                alpha = (t - a) / (b - a)\n",
    "                rel = (1.0 - alpha) * rel_a + alpha * rel_b\n",
    "                set_from_rel(t, rel)\n",
    "        else:\n",
    "            for t in range(a + 1, b):\n",
    "                set_from_rel(t, rel_a)\n",
    "# ============================================================================\n",
    "# 4. ENHANCED SMOOTHING WITH SELECTIVE APPLICATION\n",
    "# ============================================================================\n",
    "def _alpha(cutoff_hz: float, dt: float) -> float:\n",
    "    cutoff_hz = float(max(cutoff_hz, 1e-6))\n",
    "    tau = 1.0 / (2.0 * np.pi * cutoff_hz)\n",
    "    return float(1.0 / (1.0 + tau / dt))\n",
    "\n",
    "def one_euro_filter_series(\n",
    "    x: np.ndarray,\n",
    "    valid: np.ndarray,\n",
    "    fps: float,\n",
    "    min_cutoff: float,\n",
    "    beta: float,\n",
    "    d_cutoff: float,\n",
    ") -> np.ndarray:\n",
    "    T, D = x.shape\n",
    "    out = np.zeros_like(x, dtype=np.float32)\n",
    "    dt = 1.0 / float(max(fps, 1e-6))\n",
    "\n",
    "    x_prev = np.zeros(D, dtype=np.float32)\n",
    "    x_hat_prev = np.zeros(D, dtype=np.float32)\n",
    "    dx_hat_prev = np.zeros(D, dtype=np.float32)\n",
    "    has_prev = False\n",
    "\n",
    "    for t in range(T):\n",
    "        if not bool(valid[t]):\n",
    "            has_prev = False\n",
    "            continue\n",
    "\n",
    "        xt = x[t].astype(np.float32, copy=False)\n",
    "\n",
    "        if not has_prev:\n",
    "            out[t] = xt\n",
    "            x_prev = xt\n",
    "            x_hat_prev = xt\n",
    "            dx_hat_prev[:] = 0.0\n",
    "            has_prev = True\n",
    "            continue\n",
    "\n",
    "        dx = (xt - x_prev) / dt\n",
    "        a_d = _alpha(d_cutoff, dt)\n",
    "        dx_hat = a_d * dx + (1.0 - a_d) * dx_hat_prev\n",
    "\n",
    "        cutoff = float(min_cutoff + beta * np.linalg.norm(dx_hat))\n",
    "        a = _alpha(cutoff, dt)\n",
    "\n",
    "        x_hat = a * xt + (1.0 - a) * x_hat_prev\n",
    "\n",
    "        out[t] = x_hat\n",
    "        x_prev = xt\n",
    "        x_hat_prev = x_hat\n",
    "        dx_hat_prev = dx_hat\n",
    "\n",
    "    return out\n",
    "\n",
    "def smooth_points_over_time(\n",
    "    pts: np.ndarray,\n",
    "    eps: float,\n",
    "    fps: float,\n",
    "    min_cutoff: float,\n",
    "    beta: float,\n",
    "    d_cutoff: float,\n",
    ") -> None:\n",
    "    T, N, _ = pts.shape\n",
    "    for i in range(N):\n",
    "        x = pts[:, i, :]\n",
    "        valid = valid_points_xyz(x, eps=eps) & np.isfinite(x).all(axis=1)\n",
    "        if not np.any(valid):\n",
    "            continue\n",
    "        pts[:, i, :] = one_euro_filter_series(\n",
    "            x, valid=valid, fps=fps,\n",
    "            min_cutoff=min_cutoff, beta=beta, d_cutoff=d_cutoff\n",
    "        )\n",
    "# ============================================================================\n",
    "# 5. FRAME MANAGEMENT - HYBRID STRATEGY\n",
    "# ============================================================================\n",
    "def adaptive_padding(sequence: np.ndarray, target_frames: int) -> tuple:\n",
    "    \"\"\"\n",
    "    Smart padding for short sequences using interpolation.\n",
    "    Returns: (padded_sequence, attention_mask)\n",
    "    \"\"\"\n",
    "    T, D = sequence.shape\n",
    "    \n",
    "    if T >= target_frames:\n",
    "        return sequence[:target_frames], np.ones(target_frames, dtype=np.float32)\n",
    "    \n",
    "    # Create padded sequence with interpolation\n",
    "    padded_seq = np.zeros((target_frames, D), dtype=np.float32)\n",
    "    \n",
    "    # Original time points\n",
    "    x_orig = np.arange(T)\n",
    "    x_target = np.linspace(0, T-1, target_frames)\n",
    "    \n",
    "    # Interpolate each feature dimension\n",
    "    for d in range(D):\n",
    "        if np.any(np.isfinite(sequence[:, d])):\n",
    "            # Use linear interpolation\n",
    "            if T >= 2:\n",
    "                f = interpolate.interp1d(\n",
    "                    x_orig, sequence[:, d], \n",
    "                    kind='linear',\n",
    "                    bounds_error=False,\n",
    "                    fill_value=\"extrapolate\"\n",
    "                )\n",
    "                padded_seq[:, d] = f(x_target)\n",
    "            else:\n",
    "                # If only 1 frame, repeat it\n",
    "                padded_seq[:, d] = sequence[0, d]\n",
    "    \n",
    "    # Create attention mask (1 for interpolated frames close to original, 0.5 for extended)\n",
    "    mask = np.zeros(target_frames, dtype=np.float32)\n",
    "    \n",
    "    # Mark positions corresponding to original frames\n",
    "    for i, target_pos in enumerate(x_target):\n",
    "        closest_orig = int(round(target_pos))\n",
    "        if 0 <= closest_orig < T:\n",
    "            mask[i] = 1.0\n",
    "        else:\n",
    "            mask[i] = 0.5  # Extended frames\n",
    "    \n",
    "    return padded_seq, mask\n",
    "\n",
    "def create_sliding_windows(sequence: np.ndarray, window_size: int, overlap: float = 0.5) -> list:\n",
    "    \"\"\"\n",
    "    Create sliding windows for long sequences.\n",
    "    \"\"\"\n",
    "    T = sequence.shape[0]\n",
    "    windows = []\n",
    "    \n",
    "    if T <= window_size:\n",
    "        return [sequence]\n",
    "    \n",
    "    # Calculate step size\n",
    "    step = int(window_size * (1 - overlap))\n",
    "    if step < 1:\n",
    "        step = 1\n",
    "    \n",
    "    # Create windows\n",
    "    start = 0\n",
    "    while start + window_size <= T:\n",
    "        windows.append(sequence[start:start + window_size])\n",
    "        start += step\n",
    "    \n",
    "    # Always include the last window\n",
    "    if not windows or (start < T and T >= window_size):\n",
    "        last_window = sequence[-window_size:]\n",
    "        if len(windows) == 0 or not np.array_equal(last_window, windows[-1]):\n",
    "            windows.append(last_window)\n",
    "    \n",
    "    return windows\n",
    "\n",
    "def hybrid_frame_strategy(sequence: np.ndarray, original_length: int) -> tuple:\n",
    "    \"\"\"\n",
    "    FIXED VERSION: Hybrid frame strategy based on sequence length.\n",
    "    Returns (sequences_list, masks_list, metadata_list) where masks have shape (T,)\n",
    "    \"\"\"\n",
    "    T = sequence.shape[0]  # FIXED: Use actual sequence length, not original_length\n",
    "    \n",
    "    # Debug: Print actual vs original\n",
    "    if T != original_length:\n",
    "        print(f\"  Note: Sequence length changed from {original_length} to {T}\")\n",
    "    \n",
    "    if T < 30:\n",
    "        # Case 1: Very Short - Interpolation padding\n",
    "        padded_seq, mask = adaptive_padding(sequence, config.TARGET_FRAMES)\n",
    "        return [padded_seq], [mask], [{\n",
    "            'strategy': 'interpolation_padding',\n",
    "            'original_length': original_length,\n",
    "            'processed_length': T,\n",
    "            'padding_amount': config.TARGET_FRAMES - T\n",
    "        }]\n",
    "    \n",
    "    elif T < config.TARGET_FRAMES:\n",
    "        # Case 2: Short - Edge padding (repeat last frame)\n",
    "        padded_seq = np.zeros((config.TARGET_FRAMES, sequence.shape[1]), dtype=np.float32)\n",
    "        padded_seq[:T] = sequence\n",
    "        \n",
    "        if T > 0:\n",
    "            padded_seq[T:] = sequence[-1]\n",
    "        \n",
    "        mask = np.zeros(config.TARGET_FRAMES, dtype=np.float32)\n",
    "        mask[:T] = 1.0\n",
    "        \n",
    "        return [padded_seq], [mask], [{\n",
    "            'strategy': 'edge_padding',\n",
    "            'original_length': original_length,\n",
    "            'processed_length': T,\n",
    "            'padding_amount': config.TARGET_FRAMES - T\n",
    "        }]\n",
    "    \n",
    "    elif T <= config.MAX_SINGLE_FRAMES:\n",
    "        # Case 3: Medium - Take first 96 frames\n",
    "        truncated_seq = sequence[:config.TARGET_FRAMES]\n",
    "        mask = np.ones(config.TARGET_FRAMES, dtype=np.float32)\n",
    "        \n",
    "        return [truncated_seq], [mask], [{\n",
    "            'strategy': 'first_frames',\n",
    "            'original_length': original_length,\n",
    "            'processed_length': T,\n",
    "            'truncation_amount': T - config.TARGET_FRAMES\n",
    "        }]\n",
    "    \n",
    "    elif T <= config.WINDOW_THRESHOLD:\n",
    "        # Case 4: Long - Take middle 96 frames\n",
    "        middle_start = (T - config.TARGET_FRAMES) // 2\n",
    "        middle_seq = sequence[middle_start:middle_start + config.TARGET_FRAMES]\n",
    "        mask = np.ones(config.TARGET_FRAMES, dtype=np.float32)\n",
    "        \n",
    "        return [middle_seq], [mask], [{\n",
    "            'strategy': 'middle_frames',\n",
    "            'original_length': original_length,\n",
    "            'processed_length': T,\n",
    "            'middle_start': middle_start\n",
    "        }]\n",
    "    \n",
    "    else:\n",
    "        # Case 5: Very Long - Sliding windows\n",
    "        windows = create_sliding_windows(sequence, config.TARGET_FRAMES, overlap=0.5)\n",
    "        masks = [np.ones(config.TARGET_FRAMES, dtype=np.float32) for _ in windows]\n",
    "        metadata = []\n",
    "        \n",
    "        for i, window in enumerate(windows):\n",
    "            metadata.append({\n",
    "                'strategy': 'sliding_window',\n",
    "                'original_length': original_length,\n",
    "                'processed_length': T,\n",
    "                'window_index': i,\n",
    "                'total_windows': len(windows),\n",
    "                'overlap_ratio': 0.5\n",
    "            })\n",
    "        \n",
    "        return windows, masks, metadata\n",
    "# ============================================================================\n",
    "# 6. MAIN PREPROCESSING PIPELINE\n",
    "# ============================================================================\n",
    "def preprocess_sequence_global(seq: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Core preprocessing pipeline (your original function).\n",
    "    Returns cleaned sequence.\n",
    "    \"\"\"\n",
    "    y = seq.astype(np.float32, copy=True)\n",
    "    if y.ndim != 2 or y.shape[1] != config.FEATURE_DIM:\n",
    "        raise ValueError(f\"Expected shape (T,{config.FEATURE_DIM}), got {y.shape}\")\n",
    "\n",
    "    pose = y[:, :config.POSE_SIZE].reshape(-1, config.POSE_LANDMARKS, config.POSE_VALS)\n",
    "    face = y[:, config.POSE_SIZE:config.POSE_SIZE + config.FACE_SIZE].reshape(-1, config.FACE_LANDMARKS, config.FACE_VALS)\n",
    "    lh = y[:, config.POSE_SIZE + config.FACE_SIZE:config.POSE_SIZE + config.FACE_SIZE + config.HAND_SIZE].reshape(-1, config.HAND_LANDMARKS, config.HAND_VALS)\n",
    "    rh = y[:, config.POSE_SIZE + config.FACE_SIZE + config.HAND_SIZE:].reshape(-1, config.HAND_LANDMARKS, config.HAND_VALS)\n",
    "\n",
    "    # Pose cleaning\n",
    "    px, py, pz, pv = pose[:, :, 0], pose[:, :, 1], pose[:, :, 2], pose[:, :, 3]\n",
    "    finite_pose = np.isfinite(pz) & np.isfinite(pv)\n",
    "    \n",
    "    pose_in_strict = in_unit_xy(px, py) & finite_pose\n",
    "    pose_in_relaxed = reasonable_xy(px, py) & finite_pose\n",
    "    \n",
    "    critical_mask = np.zeros((pose.shape[0], config.POSE_LANDMARKS), dtype=bool)\n",
    "    for i in config.CRITICAL_POSE_IDXS:\n",
    "        critical_mask[:, i] = True\n",
    "    \n",
    "    pose_keep_for_transform = (pv >= 0.1) & pose_in_strict\n",
    "    pose_keep_for_transform = pose_keep_for_transform | (critical_mask & pose_in_relaxed)\n",
    "    \n",
    "    pose_keep_visible = (pv >= 0.1) & pose_in_strict\n",
    "    \n",
    "    bad_xyz = ~pose_keep_for_transform\n",
    "    pose[bad_xyz, :3] = 0.0\n",
    "    pose[~pose_keep_visible, 3] = 0.0\n",
    "    \n",
    "    pose[:, config.LEG_IDXS, :3] = 0.0\n",
    "    pose[:, config.LEG_IDXS, 3] = 0.0\n",
    "    \n",
    "    # Face cleaning\n",
    "    fx, fy, fz = face[:, :, 0], face[:, :, 1], face[:, :, 2]\n",
    "    face_in = reasonable_xy(fx, fy) & np.isfinite(fz)\n",
    "    face[~face_in, :3] = 0.0\n",
    "    \n",
    "    # Hands cleaning\n",
    "    lx, ly, lz = lh[:, :, 0], lh[:, :, 1], lh[:, :, 2]\n",
    "    lh_in = reasonable_xy(lx, ly) & np.isfinite(lz)\n",
    "    lh[~lh_in, :3] = 0.0\n",
    "    \n",
    "    rx, ry, rz = rh[:, :, 0], rh[:, :, 1], rh[:, :, 2]\n",
    "    rh_in = reasonable_xy(rx, ry) & np.isfinite(rz)\n",
    "    rh[~rh_in, :3] = 0.0\n",
    "    \n",
    "    # Global normalization\n",
    "    pose_xyz = pose[:, :, :3]\n",
    "    vis = pose[:, :, 3]\n",
    "    \n",
    "    root = compute_global_root(pose_xyz, vis, eps=config.EPS)\n",
    "    scale = compute_global_scale(pose_xyz, vis, root)\n",
    "    \n",
    "    pose_valid_for_transform = pose_keep_for_transform & valid_points_xyz(pose_xyz, eps=config.EPS)\n",
    "    pose_xyz[pose_valid_for_transform] = (pose_xyz[pose_valid_for_transform] - root) / scale\n",
    "    pose[:, :, :3] = pose_xyz\n",
    "    \n",
    "    for arr in (face, lh, rh):\n",
    "        m = valid_points_xyz(arr, eps=config.EPS)\n",
    "        arr[m] = (arr[m] - root) / scale\n",
    "    \n",
    "    # Wrist positions\n",
    "    lw = pose_xyz[:, 15, :].copy()\n",
    "    rw = pose_xyz[:, 16, :].copy()\n",
    "    \n",
    "    # Hand fixing\n",
    "    fix_swap_and_gate_hands(\n",
    "        lh, rh, lw, rw,\n",
    "        min_pts=8,\n",
    "        hand_wrist_max_dist=1.1,\n",
    "        eps=config.EPS,\n",
    "    )\n",
    "    \n",
    "    fill_hand_gaps_wrist_relative_tiered(\n",
    "        lh, lw,\n",
    "        small_gap=6,\n",
    "        medium_gap=15,\n",
    "        min_pts=8,\n",
    "        rel_change_thresh=0.7,\n",
    "        eps=config.EPS,\n",
    "    )\n",
    "    fill_hand_gaps_wrist_relative_tiered(\n",
    "        rh, rw,\n",
    "        small_gap=6,\n",
    "        medium_gap=15,\n",
    "        min_pts=8,\n",
    "        rel_change_thresh=0.7,\n",
    "        eps=config.EPS,\n",
    "    )\n",
    "    \n",
    "    # Smoothing\n",
    "    if config.SMOOTH_POSE:\n",
    "        smooth_points_over_time(\n",
    "            pose[:, :, :3], eps=config.EPS, fps=config.FPS,\n",
    "            min_cutoff=config.POSE_MIN_CUTOFF, beta=config.POSE_BETA, d_cutoff=config.D_CUTOFF\n",
    "        )\n",
    "    if config.SMOOTH_HANDS:\n",
    "        smooth_points_over_time(\n",
    "            lh, eps=config.EPS, fps=config.FPS,\n",
    "            min_cutoff=config.HAND_MIN_CUTOFF, beta=config.HAND_BETA, d_cutoff=config.D_CUTOFF\n",
    "        )\n",
    "        smooth_points_over_time(\n",
    "            rh, eps=config.EPS, fps=config.FPS,\n",
    "            min_cutoff=config.HAND_MIN_CUTOFF, beta=config.HAND_BETA, d_cutoff=config.D_CUTOFF\n",
    "        )\n",
    "    if config.SMOOTH_FACE:\n",
    "        smooth_points_over_time(\n",
    "            face, eps=config.EPS, fps=config.FPS,\n",
    "            min_cutoff=config.FACE_MIN_CUTOFF, beta=config.FACE_BETA, d_cutoff=config.D_CUTOFF\n",
    "        )\n",
    "    \n",
    "    # Reconstruct\n",
    "    out = np.empty_like(y, dtype=np.float32)\n",
    "    out[:, :config.POSE_SIZE] = pose.reshape(-1, config.POSE_SIZE)\n",
    "    out[:, config.POSE_SIZE:config.POSE_SIZE + config.FACE_SIZE] = face.reshape(-1, config.FACE_SIZE)\n",
    "    out[:, config.POSE_SIZE + config.FACE_SIZE:config.POSE_SIZE + config.FACE_SIZE + config.HAND_SIZE] = lh.reshape(-1, config.HAND_SIZE)\n",
    "    out[:, config.POSE_SIZE + config.FACE_SIZE + config.HAND_SIZE:] = rh.reshape(-1, config.HAND_SIZE)\n",
    "    \n",
    "    return out\n",
    "# ============================================================================\n",
    "# FIXED: FILENAME HANDLING WITH SAFE CHARACTERS\n",
    "# ============================================================================\n",
    "import re\n",
    "\n",
    "def sanitize_filename(filename: str) -> str:\n",
    "    \"\"\"\n",
    "    Sanitize filename by removing special characters.\n",
    "    Keeps only alphanumeric, underscores, and dots.\n",
    "    \"\"\"\n",
    "    # Remove special characters but keep alphanumeric, underscore, dot\n",
    "    sanitized = re.sub(r'[^a-zA-Z0-9_.]', '_', filename)\n",
    "    # Remove multiple consecutive underscores\n",
    "    sanitized = re.sub(r'_+', '_', sanitized)\n",
    "    # Remove leading/trailing underscores\n",
    "    sanitized = sanitized.strip('_')\n",
    "    return sanitized\n",
    "\n",
    "def create_safe_filename(source: str, word: str, video_id: str, window_idx: int = None) -> tuple:\n",
    "    \"\"\"\n",
    "    Create safe filenames for processed files and masks.\n",
    "    source parameter is ignored (removed from filename)\n",
    "    \"\"\"\n",
    "    safe_word = sanitize_filename(word)\n",
    "    safe_video_id = sanitize_filename(video_id)\n",
    "    \n",
    "    # Base filename: only word + video_id\n",
    "    if window_idx is None:\n",
    "        base_name = f\"{safe_word}_{safe_video_id}\"\n",
    "    else:\n",
    "        base_name = f\"{safe_word}_{safe_video_id}_w{window_idx:02d}\"\n",
    "    \n",
    "    # Full filenames\n",
    "    processed_filename = f\"{base_name}.npy\"\n",
    "    mask_filename = f\"{base_name}_mask.npy\"\n",
    "    \n",
    "    return base_name, processed_filename, mask_filename\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# UPDATED: PROCESS SINGLE VIDEO FUNCTION\n",
    "# ============================================================================\n",
    "def process_single_video_fixed(filepath: str, word: str, source: str, video_id: str) -> list:\n",
    "    \"\"\"\n",
    "    Process a single video file with safe filename handling.\n",
    "    Returns list of processed records.\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    \n",
    "    try:\n",
    "        # Load raw data\n",
    "        raw_data = np.load(filepath, allow_pickle=True)\n",
    "        original_length = raw_data.shape[0]\n",
    "        \n",
    "        # Apply core preprocessing\n",
    "        cleaned_data = preprocess_sequence_global(raw_data)\n",
    "        \n",
    "        # Debug: Check shape\n",
    "        print(f\"  Original: {raw_data.shape}, Cleaned: {cleaned_data.shape}\")\n",
    "        \n",
    "        # Apply hybrid frame strategy\n",
    "        sequences, masks, metadata = hybrid_frame_strategy(cleaned_data, original_length)\n",
    "        \n",
    "        # DEBUG: Show what hybrid strategy produced\n",
    "        print(f\"  → Strategy produced {len(sequences)} sequence(s)\")\n",
    "        for i, (seq, mask) in enumerate(zip(sequences, masks)):\n",
    "            print(f\"    Seq {i+1}: shape={seq.shape}, mask={mask.shape}\")\n",
    "            print(f\"    Strategy: {metadata[i]['strategy']}\")\n",
    "        \n",
    "        # VERIFY SHAPES BEFORE SAVING\n",
    "        for seq_idx, (seq, mask, meta) in enumerate(zip(sequences, masks, metadata)):\n",
    "            # CRITICAL: Check if shapes are correct\n",
    "            if seq.shape != (config.TARGET_FRAMES, config.FEATURE_DIM):\n",
    "                print(f\"  ⚠️ WARNING: Sequence shape {seq.shape}, expected (96, 438)!\")\n",
    "                # Fix it\n",
    "                if seq.shape[0] < config.TARGET_FRAMES:\n",
    "                    # Pad with zeros\n",
    "                    padded = np.zeros((config.TARGET_FRAMES, config.FEATURE_DIM))\n",
    "                    padded[:seq.shape[0]] = seq\n",
    "                    seq = padded\n",
    "                    print(f\"  → Padded from {seq.shape[0]} to {config.TARGET_FRAMES} frames\")\n",
    "                else:\n",
    "                    # Truncate\n",
    "                    seq = seq[:config.TARGET_FRAMES]\n",
    "                    print(f\"  → Truncated from {seq.shape[0]} to {config.TARGET_FRAMES} frames\")\n",
    "            \n",
    "            if mask.shape != (config.TARGET_FRAMES,):\n",
    "                print(f\"  ⚠️ WARNING: Mask shape {mask.shape}, expected (96,)!\")\n",
    "                # Fix it\n",
    "                if mask.shape[0] < config.TARGET_FRAMES:\n",
    "                    padded_mask = np.zeros(config.TARGET_FRAMES)\n",
    "                    padded_mask[:mask.shape[0]] = mask\n",
    "                    mask = padded_mask\n",
    "                else:\n",
    "                    mask = mask[:config.TARGET_FRAMES]\n",
    "            \n",
    "            # Generate safe filenames\n",
    "            window_idx = None if len(sequences) == 1 else seq_idx\n",
    "            base_name, processed_filename, mask_filename = create_safe_filename(\n",
    "                source, word, video_id, window_idx\n",
    "            )\n",
    "            \n",
    "            save_path = config.OUTPUT_DIR / processed_filename\n",
    "            mask_path = config.OUTPUT_DIR / mask_filename\n",
    "            \n",
    "            # Save data\n",
    "            np.save(save_path, seq)\n",
    "            np.save(mask_path, mask)\n",
    "            \n",
    "            # Create record\n",
    "            records.append({\n",
    "                'word': word,\n",
    "                'original_file': filepath,\n",
    "                'processed_file': str(save_path),\n",
    "                'mask_file': str(mask_path),\n",
    "                'source': source,\n",
    "                'video_id': video_id,\n",
    "                'original_length': original_length,\n",
    "                'processed_length': seq.shape[0],\n",
    "                'strategy': meta['strategy'],\n",
    "                'is_windowed': meta['strategy'] == 'sliding_window',\n",
    "                'window_index': meta.get('window_index', 0),\n",
    "                'total_windows': meta.get('total_windows', 1),\n",
    "                'padding_amount': meta.get('padding_amount', 0),\n",
    "                'truncation_amount': meta.get('truncation_amount', 0),\n",
    "                'base_filename': base_name\n",
    "            })\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filepath}: {e}\")\n",
    "    \n",
    "    return records\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# UPDATED: SCAN DATASETS FUNCTION WITH BETTER ERROR HANDLING\n",
    "# ============================================================================\n",
    "import re\n",
    "\n",
    "def scan_datasets():\n",
    "    \"\"\"Scan only MSASL_RAW_DIR (your single folder) and fix word extraction.\"\"\"\n",
    "    print(\"Scanning dataset...\")\n",
    "\n",
    "    def scan_dir(path, source_name):\n",
    "        data = []\n",
    "        if not path.exists():\n",
    "            print(f\"⚠️ {source_name} directory not found: {path}\")\n",
    "            return data\n",
    "\n",
    "        files = list(path.glob(\"*.npy\"))\n",
    "        print(f\"Found {len(files)} .npy files in {source_name}\")\n",
    "\n",
    "        for f in tqdm(files, desc=f\"Scanning {source_name}\"):\n",
    "            try:\n",
    "                filename = f.stem  # \"ABOUT 5\"\n",
    "                \n",
    "                # Split word and numeric ID at the end\n",
    "                match = re.match(r\"(.+?)\\s*(\\d+)$\", filename)\n",
    "                if match:\n",
    "                    word = match.group(1)\n",
    "                    video_id = match.group(2)\n",
    "                else:\n",
    "                    word = filename\n",
    "                    video_id = \"unknown\"\n",
    "                \n",
    "                word = word.lower().strip()\n",
    "                \n",
    "                data.append({\n",
    "                    'filepath': str(f),\n",
    "                    'word': word,\n",
    "                    'source': source_name,\n",
    "                    'video_id': video_id,\n",
    "                    'original_filename': filename\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"  ⚠️ Error parsing {f.name}: {e}\")\n",
    "                continue\n",
    "        return data\n",
    "\n",
    "    msasl_data = scan_dir(config.MSASL_RAW_DIR, \"TOP_CLASSES\")\n",
    "    df = pd.DataFrame(msasl_data)\n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 10. SIMPLIFIED PROCESSING (Minimal Prints)\n",
    "# ============================================================================\n",
    "def process_all_videos_silent():\n",
    "    \"\"\"Main processing pipeline with minimal output.\"\"\"\n",
    "    # Ensure output directory exists\n",
    "    config.OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Scan datasets\n",
    "    df = scan_datasets()\n",
    "    if df.empty:\n",
    "        print(\"❌ No files found!\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Found {len(df):,} videos\")\n",
    "    \n",
    "    # Filter rare words\n",
    "    word_counts = df['word'].value_counts()\n",
    "    valid_words = word_counts[word_counts >= config.MIN_SAMPLES_PER_WORD].index\n",
    "    df_filtered = df[df['word'].isin(valid_words)].copy()\n",
    "    \n",
    "    print(f\"Processing {len(df_filtered):,} videos after filtering...\")\n",
    "    \n",
    "    # Process videos\n",
    "    all_records = []\n",
    "    stats = defaultdict(int)\n",
    "    \n",
    "    for idx, row in tqdm(df_filtered.iterrows(), total=len(df_filtered), desc=\"Processing\"):\n",
    "        # FIXED: Call the renamed function\n",
    "        records = process_single_video_fixed(\n",
    "            row['filepath'],\n",
    "            row['word'],\n",
    "            row['source'],\n",
    "            row['video_id']\n",
    "        )\n",
    "        \n",
    "        if records:\n",
    "            all_records.extend(records)\n",
    "            for record in records:\n",
    "                stats[record['strategy']] += 1\n",
    "                stats['total'] += 1\n",
    "    \n",
    "    if not all_records:\n",
    "        print(\"❌ No videos processed!\")\n",
    "        return None\n",
    "    \n",
    "    # Save metadata\n",
    "    df_processed = pd.DataFrame(all_records)\n",
    "    df_processed.to_csv(config.OUTPUT_DIR / \"metadata.csv\", index=False)\n",
    "    \n",
    "    # Print quick summary\n",
    "    print(f\"\\n✅ Done: {stats['total']:,} samples generated\")\n",
    "    for strategy in ['interpolation_padding', 'edge_padding', 'first_frames', \n",
    "                     'middle_frames', 'sliding_window']:\n",
    "        if strategy in stats:\n",
    "            print(f\"  {strategy}: {stats[strategy]:,}\")\n",
    "    \n",
    "    return df_processed\n",
    "def test_few_files():\n",
    "    \"\"\"Test the fixed code on 3 files to see what hybrid_frame_strategy produces.\"\"\"\n",
    "    print(\"🧪 Testing hybrid_frame_strategy on sample files...\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Find a few files\n",
    "    test_files = list(config.MSASL_RAW_DIR.glob(\"*.npy\"))[:3]\n",
    "    \n",
    "    for filepath in test_files:\n",
    "        print(f\"\\nFile: {filepath.name}\")\n",
    "        try:\n",
    "            raw_data = np.load(filepath, allow_pickle=True)\n",
    "            print(f\"  Original: {raw_data.shape}\")\n",
    "            \n",
    "            cleaned = preprocess_sequence_global(raw_data)\n",
    "            print(f\"  Cleaned: {cleaned.shape}\")\n",
    "            \n",
    "            sequences, masks, metadata = hybrid_frame_strategy(cleaned, raw_data.shape[0])\n",
    "            \n",
    "            print(f\"  Strategy: {metadata[0]['strategy']}\")\n",
    "            print(f\"  Produced {len(sequences)} sequence(s):\")\n",
    "            \n",
    "            for i, (seq, mask) in enumerate(zip(sequences, masks)):\n",
    "                print(f\"    Sequence {i+1}: {seq.shape}\")\n",
    "                print(f\"    Mask {i+1}: {mask.shape}\")\n",
    "                \n",
    "                # Check if it's 96 frames\n",
    "                if seq.shape == (config.TARGET_FRAMES, config.FEATURE_DIM):\n",
    "                    print(f\"    ✅ Correct shape!\")\n",
    "                else:\n",
    "                    print(f\"    ❌ Wrong shape! Expected (96, 438)\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"  Error: {e}\")\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "# ========================================================================\n",
    "# WEBCAM INFERENCE USING EXACT SAME PREPROCESSING PIPELINE\n",
    "# ========================================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import deque\n",
    "import cv2\n",
    "\n",
    "# ==============================\n",
    "# LOAD TRAINED MODEL\n",
    "# ==============================\n",
    "\n",
    "MODEL_PATH = r\"tcn_best_cpu_3rdcode.pth\"\n",
    "LABEL_PATH = r\"label_encoder_3rdcode.npy\"\n",
    "\n",
    "LABELS = np.load(LABEL_PATH)\n",
    "\n",
    "DEVICE = \"cpu\"\n",
    "\n",
    "# ---- TCN (same architecture as training) ----\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, ic, oc, d):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(ic, oc, 3, padding=d, dilation=d),\n",
    "            nn.BatchNorm1d(oc),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(oc, oc, 3, padding=d, dilation=d),\n",
    "            nn.BatchNorm1d(oc),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.res = nn.Conv1d(ic, oc, 1) if ic != oc else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.net(x)\n",
    "        y = y[..., :x.size(2)]\n",
    "        return y + self.res(x)\n",
    "\n",
    "class TCN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        chans = [192, 192, 192, 192]\n",
    "        layers = []\n",
    "        for i, c in enumerate(chans):\n",
    "            layers.append(\n",
    "                TemporalBlock(\n",
    "                    config.FEATURE_DIM if i == 0 else chans[i-1],\n",
    "                    c, 2 ** i\n",
    "                )\n",
    "            )\n",
    "        self.tcn = nn.Sequential(*layers)\n",
    "        self.fc = nn.Linear(chans[-1], num_classes)\n",
    "\n",
    "    def masked_pool(self, x, m):\n",
    "        m = m.unsqueeze(1)\n",
    "        return (x * m).sum(2) / (m.sum(2) + 1e-6)\n",
    "\n",
    "    def forward(self, x, m):\n",
    "        x = self.tcn(x)\n",
    "        x = self.masked_pool(x, m)\n",
    "        return self.fc(x)\n",
    "\n",
    "model = TCN(len(LABELS)).to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "# ==============================\n",
    "# WEBCAM LOOP\n",
    "# ==============================\n",
    "\n",
    "buffer = []\n",
    "recording = False\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "print(\"Press R to start recording\")\n",
    "print(\"Press E to end recording and predict\")\n",
    "print(\"Press Q to quit\")\n",
    "\n",
    "while cap.isOpened():\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    rgb.flags.writeable = False\n",
    "    results = holistic.process(rgb)\n",
    "\n",
    "    # === EXACT SAME LANDMARK EXTRACTION ===\n",
    "    if results.pose_landmarks:\n",
    "        pose = np.array([[lm.x, lm.y, lm.z, lm.visibility]\n",
    "                         for lm in results.pose_landmarks.landmark]).flatten()\n",
    "    else:\n",
    "        pose = np.zeros(33 * 4)\n",
    "\n",
    "    if results.left_hand_landmarks:\n",
    "        lh = np.array([[lm.x, lm.y, lm.z]\n",
    "                       for lm in results.left_hand_landmarks.landmark]).flatten()\n",
    "    else:\n",
    "        lh = np.zeros(21 * 3)\n",
    "\n",
    "    if results.right_hand_landmarks:\n",
    "        rh = np.array([[lm.x, lm.y, lm.z]\n",
    "                       for lm in results.right_hand_landmarks.landmark]).flatten()\n",
    "    else:\n",
    "        rh = np.zeros(21 * 3)\n",
    "\n",
    "    if results.face_landmarks:\n",
    "        relevant = [results.face_landmarks.landmark[i] for i in RELEVANT_FACE_INDICES]\n",
    "        face = np.array([[lm.x, lm.y, lm.z] for lm in relevant]).flatten()\n",
    "    else:\n",
    "        face = np.zeros(len(RELEVANT_FACE_INDICES) * 3)\n",
    "\n",
    "    final_kp = np.concatenate([pose, face, lh, rh])\n",
    "\n",
    "    if recording:\n",
    "        buffer.append(final_kp)\n",
    "\n",
    "    cv2.imshow(\"ASL Webcam\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # ==============================\n",
    "    # START RECORDING\n",
    "    # ==============================\n",
    "    if key == ord('r'):\n",
    "        buffer = []\n",
    "        recording = True\n",
    "        print(\"Recording...\")\n",
    "\n",
    "    # ==============================\n",
    "    # STOP RECORDING + PREDICT\n",
    "    # ==============================\n",
    "    if key == ord('e'):\n",
    "        recording = False\n",
    "\n",
    "        if len(buffer) < 5:\n",
    "            print(\"Too short.\")\n",
    "            continue\n",
    "\n",
    "        raw_sequence = np.array(buffer)\n",
    "        original_length = raw_sequence.shape[0]\n",
    "\n",
    "        print(f\"Captured {original_length} frames\")\n",
    "\n",
    "        # 1️⃣ EXACT PREPROCESSING\n",
    "        cleaned = preprocess_sequence_global(raw_sequence)\n",
    "\n",
    "        # 2️⃣ EXACT HYBRID STRATEGY\n",
    "        sequences, masks, metadata = hybrid_frame_strategy(\n",
    "            cleaned,\n",
    "            original_length\n",
    "        )\n",
    "\n",
    "        # If sliding windows → average predictions\n",
    "        all_probs = []\n",
    "\n",
    "        for seq, mask in zip(sequences, masks):\n",
    "\n",
    "            if seq.shape != (config.TARGET_FRAMES, config.FEATURE_DIM):\n",
    "                continue\n",
    "\n",
    "            x = torch.from_numpy(seq).float().unsqueeze(0).transpose(1, 2)\n",
    "            m = torch.from_numpy(mask).float().unsqueeze(0)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(x, m)\n",
    "                probs = torch.softmax(logits, dim=1)\n",
    "\n",
    "            all_probs.append(probs[0].numpy())\n",
    "\n",
    "        if len(all_probs) == 0:\n",
    "            print(\"No valid sequences.\")\n",
    "            continue\n",
    "\n",
    "        mean_probs = np.mean(np.stack(all_probs), axis=0)\n",
    "\n",
    "        top_idx = np.argmax(mean_probs)\n",
    "        confidence = mean_probs[top_idx]\n",
    "\n",
    "        print(f\"\\nPrediction: {LABELS[top_idx]} ({confidence:.3f})\")\n",
    "        print(f\"Strategy used: {metadata[0]['strategy']}\")\n",
    "\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed322f95-23f9-4158-b502-490cd98b28df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (venv310)",
   "language": "python",
   "name": "venv310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
