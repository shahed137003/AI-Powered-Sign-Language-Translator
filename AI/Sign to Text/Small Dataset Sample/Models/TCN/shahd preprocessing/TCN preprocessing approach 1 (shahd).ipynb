{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc910636-c87a-4bf0-af24-f4d26f8bd502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples after filtering: 5568\n",
      "Number of classes: 146\n",
      "E001 | TL 4.487 TA 0.084 | VL 4.016 VA 0.165\n",
      "E002 | TL 3.675 TA 0.187 | VL 3.396 VA 0.233\n",
      "E003 | TL 3.291 TA 0.267 | VL 3.242 VA 0.293\n",
      "E004 | TL 3.029 TA 0.341 | VL 3.461 VA 0.228\n",
      "E005 | TL 2.854 TA 0.382 | VL 3.251 VA 0.289\n",
      "E006 | TL 2.683 TA 0.439 | VL 2.672 VA 0.440\n",
      "E007 | TL 2.555 TA 0.485 | VL 3.167 VA 0.352\n",
      "E008 | TL 2.418 TA 0.531 | VL 2.814 VA 0.463\n",
      "E009 | TL 2.317 TA 0.563 | VL 3.425 VA 0.300\n",
      "E010 | TL 2.212 TA 0.590 | VL 3.434 VA 0.329\n",
      "E011 | TL 2.140 TA 0.629 | VL 2.431 VA 0.566\n",
      "E012 | TL 2.094 TA 0.636 | VL 2.471 VA 0.576\n",
      "E013 | TL 2.024 TA 0.670 | VL 4.161 VA 0.262\n",
      "E014 | TL 1.959 TA 0.685 | VL 2.738 VA 0.499\n",
      "E015 | TL 1.903 TA 0.699 | VL 2.432 VA 0.582\n",
      "E016 | TL 1.857 TA 0.726 | VL 2.145 VA 0.654\n",
      "E017 | TL 1.807 TA 0.740 | VL 2.535 VA 0.539\n",
      "E018 | TL 1.771 TA 0.750 | VL 2.152 VA 0.662\n",
      "E019 | TL 1.729 TA 0.771 | VL 2.453 VA 0.573\n",
      "E020 | TL 1.696 TA 0.788 | VL 2.746 VA 0.508\n",
      "E021 | TL 1.653 TA 0.793 | VL 2.104 VA 0.670\n",
      "E022 | TL 1.609 TA 0.810 | VL 2.229 VA 0.614\n",
      "E023 | TL 1.592 TA 0.809 | VL 2.166 VA 0.670\n",
      "E024 | TL 1.568 TA 0.825 | VL 2.328 VA 0.605\n",
      "E025 | TL 1.524 TA 0.837 | VL 2.219 VA 0.612\n",
      "E026 | TL 1.487 TA 0.853 | VL 2.254 VA 0.645\n",
      "E027 | TL 1.482 TA 0.855 | VL 1.989 VA 0.722\n",
      "E028 | TL 1.443 TA 0.869 | VL 2.105 VA 0.686\n",
      "E029 | TL 1.429 TA 0.872 | VL 1.976 VA 0.706\n",
      "E030 | TL 1.411 TA 0.880 | VL 2.122 VA 0.652\n",
      "E031 | TL 1.409 TA 0.881 | VL 2.015 VA 0.707\n",
      "E032 | TL 1.369 TA 0.893 | VL 2.185 VA 0.655\n",
      "E033 | TL 1.359 TA 0.893 | VL 1.910 VA 0.713\n",
      "E034 | TL 1.322 TA 0.909 | VL 2.245 VA 0.625\n",
      "E035 | TL 1.319 TA 0.911 | VL 2.004 VA 0.686\n",
      "E036 | TL 1.287 TA 0.925 | VL 1.862 VA 0.756\n",
      "E037 | TL 1.279 TA 0.925 | VL 2.088 VA 0.697\n",
      "E038 | TL 1.270 TA 0.924 | VL 1.915 VA 0.720\n",
      "E039 | TL 1.244 TA 0.934 | VL 1.966 VA 0.707\n",
      "E040 | TL 1.238 TA 0.935 | VL 1.890 VA 0.729\n",
      "E041 | TL 1.230 TA 0.936 | VL 1.853 VA 0.725\n",
      "E042 | TL 1.216 TA 0.943 | VL 1.945 VA 0.709\n",
      "E043 | TL 1.203 TA 0.944 | VL 1.955 VA 0.732\n",
      "E044 | TL 1.189 TA 0.949 | VL 1.860 VA 0.740\n",
      "E045 | TL 1.190 TA 0.948 | VL 1.930 VA 0.697\n",
      "E046 | TL 1.170 TA 0.954 | VL 1.832 VA 0.756\n",
      "E047 | TL 1.166 TA 0.957 | VL 1.803 VA 0.763\n",
      "E048 | TL 1.139 TA 0.967 | VL 1.815 VA 0.750\n",
      "E049 | TL 1.138 TA 0.966 | VL 1.799 VA 0.752\n",
      "E050 | TL 1.127 TA 0.968 | VL 1.944 VA 0.702\n",
      "E051 | TL 1.130 TA 0.966 | VL 1.842 VA 0.740\n",
      "E052 | TL 1.112 TA 0.969 | VL 1.726 VA 0.783\n",
      "E053 | TL 1.109 TA 0.973 | VL 1.774 VA 0.770\n",
      "E054 | TL 1.097 TA 0.971 | VL 1.726 VA 0.765\n",
      "E055 | TL 1.101 TA 0.974 | VL 1.756 VA 0.779\n",
      "E056 | TL 1.083 TA 0.980 | VL 1.742 VA 0.785\n",
      "E057 | TL 1.087 TA 0.973 | VL 1.706 VA 0.763\n",
      "E058 | TL 1.076 TA 0.979 | VL 1.749 VA 0.759\n",
      "E059 | TL 1.065 TA 0.981 | VL 1.754 VA 0.763\n",
      "E060 | TL 1.066 TA 0.979 | VL 1.746 VA 0.776\n",
      "E061 | TL 1.059 TA 0.983 | VL 1.697 VA 0.779\n",
      "E062 | TL 1.052 TA 0.980 | VL 1.700 VA 0.792\n",
      "E063 | TL 1.054 TA 0.985 | VL 1.699 VA 0.781\n",
      "E064 | TL 1.050 TA 0.980 | VL 1.702 VA 0.783\n",
      "E065 | TL 1.037 TA 0.987 | VL 1.726 VA 0.772\n",
      "E066 | TL 1.031 TA 0.990 | VL 1.696 VA 0.781\n",
      "E067 | TL 1.034 TA 0.987 | VL 1.692 VA 0.790\n",
      "E068 | TL 1.033 TA 0.985 | VL 1.651 VA 0.806\n",
      "E069 | TL 1.021 TA 0.989 | VL 1.664 VA 0.797\n",
      "E070 | TL 1.027 TA 0.988 | VL 1.662 VA 0.790\n",
      "E071 | TL 1.022 TA 0.988 | VL 1.679 VA 0.788\n",
      "E072 | TL 1.016 TA 0.991 | VL 1.665 VA 0.795\n",
      "E073 | TL 1.013 TA 0.990 | VL 1.674 VA 0.794\n",
      "E074 | TL 1.013 TA 0.991 | VL 1.657 VA 0.792\n",
      "E075 | TL 1.000 TA 0.991 | VL 1.666 VA 0.786\n",
      "E076 | TL 1.001 TA 0.994 | VL 1.663 VA 0.792\n",
      "E077 | TL 0.997 TA 0.994 | VL 1.666 VA 0.799\n",
      "E078 | TL 1.003 TA 0.994 | VL 1.665 VA 0.795\n",
      "E079 | TL 1.004 TA 0.991 | VL 1.642 VA 0.806\n",
      "E080 | TL 1.000 TA 0.993 | VL 1.671 VA 0.785\n",
      "E081 | TL 0.998 TA 0.995 | VL 1.642 VA 0.813\n",
      "E082 | TL 1.003 TA 0.992 | VL 1.628 VA 0.804\n",
      "E083 | TL 0.993 TA 0.993 | VL 1.638 VA 0.797\n",
      "E084 | TL 1.001 TA 0.993 | VL 1.641 VA 0.810\n",
      "E085 | TL 1.000 TA 0.992 | VL 1.635 VA 0.801\n",
      "E086 | TL 0.998 TA 0.994 | VL 1.628 VA 0.813\n",
      "E087 | TL 0.996 TA 0.993 | VL 1.641 VA 0.797\n",
      "E088 | TL 0.995 TA 0.995 | VL 1.645 VA 0.803\n",
      "E089 | TL 0.995 TA 0.994 | VL 1.636 VA 0.801\n",
      "E090 | TL 0.995 TA 0.994 | VL 1.632 VA 0.815\n",
      "\n",
      "==============================\n",
      "TEST LOSS: 1.5604\n",
      "TEST ACC : 0.8115\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CPU-SAFE TCN FOR ASL LANDMARKS (TRAINING) - NEW DATASET\n",
    "# MODEL COMPLETELY UNCHANGED\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG\n",
    "# ============================================================\n",
    "\n",
    "DATA_DIR = Path(r\"E:\\ASL_Citizen\\NEW\\preprocessed_approach1_shahd\")\n",
    "DEVICE = \"cpu\"\n",
    "\n",
    "TARGET_FRAMES = 512\n",
    "FEATURE_DIM   = 270\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 90\n",
    "LR = 3e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "\n",
    "PATIENCE = 12\n",
    "GRAD_CLIP = 1.0\n",
    "LABEL_SMOOTH = 0.1\n",
    "\n",
    "MODEL_SAVE_PATH = DATA_DIR / \"tcn_best_cpu_approach1.pth\"\n",
    "LABEL_ENCODER_PATH = DATA_DIR / \"label_encoder_approach1.npy\"\n",
    "\n",
    "# ============================================================\n",
    "# LOAD FILES (NO MASKS IN THIS DATASET)\n",
    "# ============================================================\n",
    "\n",
    "files, labels = [], []\n",
    "\n",
    "for f in DATA_DIR.glob(\"*.npy\"):\n",
    "    arr = np.load(f)\n",
    "\n",
    "    if arr.shape != (TARGET_FRAMES, FEATURE_DIM):\n",
    "        continue\n",
    "\n",
    "    # Extract label correctly:\n",
    "    # \"ABOUT.npy\" → ABOUT\n",
    "    # \"ABOUT 2.npy\" → ABOUT\n",
    "    label = f.stem.split(\" \")[0]\n",
    "\n",
    "    files.append(str(f))\n",
    "    labels.append(label)\n",
    "\n",
    "# Remove rare classes (same logic as original)\n",
    "cnt = Counter(labels)\n",
    "keep = [i for i, y in enumerate(labels) if cnt[y] >= 2]\n",
    "\n",
    "files = [files[i] for i in keep]\n",
    "labels = [labels[i] for i in keep]\n",
    "print(\"Total samples after filtering:\", len(files))\n",
    "print(\"Number of classes:\", len(set(labels)))\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(labels)\n",
    "np.save(LABEL_ENCODER_PATH, le.classes_)\n",
    "num_classes = len(le.classes_)\n",
    "\n",
    "# ============================================================\n",
    "# SPLITS\n",
    "# ============================================================\n",
    "\n",
    "X_tr, X_tmp, y_tr, y_tmp = train_test_split(\n",
    "    files, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "X_val, X_te, y_val, y_te = train_test_split(\n",
    "    X_tmp, y_tmp, test_size=0.5, stratify=y_tmp, random_state=42\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# DATASET (GENERATES DUMMY MASK = ALL ONES)\n",
    "# ============================================================\n",
    "\n",
    "class ASLDataset(Dataset):\n",
    "    def __init__(self, files, labels):\n",
    "        self.files = files\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = np.load(self.files[idx])\n",
    "        x = torch.from_numpy(x).float().transpose(0, 1)  # (C, T)\n",
    "\n",
    "        # Create FULL mask (since no padding in this dataset)\n",
    "        m = torch.ones(TARGET_FRAMES).float()\n",
    "\n",
    "        y = torch.tensor(self.labels[idx])\n",
    "        return x, m, y\n",
    "\n",
    "train_loader = DataLoader(ASLDataset(X_tr, y_tr), BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(ASLDataset(X_val, y_val), BATCH_SIZE)\n",
    "test_loader  = DataLoader(ASLDataset(X_te, y_te), BATCH_SIZE)\n",
    "\n",
    "# ============================================================\n",
    "# MODEL (UNCHANGED EXACTLY)\n",
    "# ============================================================\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, ic, oc, d):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(ic, oc, 3, padding=d, dilation=d),\n",
    "            nn.BatchNorm1d(oc),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(oc, oc, 3, padding=d, dilation=d),\n",
    "            nn.BatchNorm1d(oc),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.res = nn.Conv1d(ic, oc, 1) if ic != oc else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.net(x)\n",
    "        y = y[..., :x.size(2)]\n",
    "        return y + self.res(x)\n",
    "\n",
    "class TCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        chans = [192, 192, 192, 192]\n",
    "        layers = []\n",
    "        for i, c in enumerate(chans):\n",
    "            layers.append(TemporalBlock(\n",
    "                FEATURE_DIM if i == 0 else chans[i-1],\n",
    "                c, 2 ** i\n",
    "            ))\n",
    "        self.tcn = nn.Sequential(*layers)\n",
    "        self.fc = nn.Linear(chans[-1], num_classes)\n",
    "\n",
    "    def masked_pool(self, x, m):\n",
    "        m = m.unsqueeze(1)\n",
    "        return (x * m).sum(2) / (m.sum(2) + 1e-6)\n",
    "\n",
    "    def forward(self, x, m):\n",
    "        x = self.tcn(x)\n",
    "        x = self.masked_pool(x, m)\n",
    "        return self.fc(x)\n",
    "\n",
    "model = TCN().to(DEVICE)\n",
    "\n",
    "# ============================================================\n",
    "# LOSS (UNCHANGED)\n",
    "# ============================================================\n",
    "\n",
    "weights = compute_class_weight(\"balanced\", classes=np.unique(y_tr), y=y_tr)\n",
    "weights = torch.tensor(weights).float()\n",
    "\n",
    "class SmoothCE(nn.Module):\n",
    "    def __init__(self, eps=0.1):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, logits, target):\n",
    "        n = logits.size(1)\n",
    "        logp = torch.log_softmax(logits, 1)\n",
    "        y = torch.zeros_like(logp).fill_(self.eps / n)\n",
    "        y.scatter_(1, target.unsqueeze(1), 1 - self.eps)\n",
    "        return -(y * logp).sum(1).mean()\n",
    "\n",
    "criterion = SmoothCE(LABEL_SMOOTH)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), LR, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = CosineAnnealingLR(optimizer, EPOCHS)\n",
    "\n",
    "# ============================================================\n",
    "# TRAIN\n",
    "# ============================================================\n",
    "\n",
    "def run(loader, train=True):\n",
    "    model.train() if train else model.eval()\n",
    "    loss_sum, correct, total = 0, 0, 0\n",
    "\n",
    "    with torch.set_grad_enabled(train):\n",
    "        for x, m, y in loader:\n",
    "            x, m, y = x.to(DEVICE), m.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "            out = model(x, m)\n",
    "            loss = criterion(out, y)\n",
    "\n",
    "            if train:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
    "                optimizer.step()\n",
    "\n",
    "            loss_sum += loss.item() * y.size(0)\n",
    "            correct += (out.argmax(1) == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "    return loss_sum / total, correct / total\n",
    "\n",
    "best, patience = -1e9, 0\n",
    "\n",
    "for e in range(EPOCHS):\n",
    "    tr_l, tr_a = run(train_loader, True)\n",
    "    va_l, va_a = run(val_loader, False)\n",
    "    scheduler.step()\n",
    "\n",
    "    metric = va_a - va_l\n",
    "\n",
    "    print(f\"E{e+1:03d} | TL {tr_l:.3f} TA {tr_a:.3f} | VL {va_l:.3f} VA {va_a:.3f}\")\n",
    "\n",
    "    if metric > best:\n",
    "        best = metric\n",
    "        patience = 0\n",
    "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "    else:\n",
    "        patience += 1\n",
    "        if patience >= PATIENCE:\n",
    "            break\n",
    "\n",
    "# ============================================================\n",
    "# TEST EVALUATION\n",
    "# ============================================================\n",
    "\n",
    "model.load_state_dict(torch.load(MODEL_SAVE_PATH, map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "test_loss, test_acc = run(test_loader, train=False)\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(f\"TEST LOSS: {test_loss:.4f}\")\n",
    "print(f\"TEST ACC : {test_acc:.4f}\")\n",
    "print(\"==============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88de2fa-d370-4dd4-bba0-ceda9cfb32e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (venv310)",
   "language": "python",
   "name": "venv310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
