{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f6bcb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import mediapipe as mp \n",
    "import cv2 as cv\n",
    "import os \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbc09c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5076 5076\n"
     ]
    }
   ],
   "source": [
    "## let's load the extracted landmarks \n",
    "\n",
    "file_path_Dataset='Top_Classes_Landmarks/Top_Classes_Landmarks'\n",
    "file_path_Preprocessed='Top_Classes_Landmarks_Preprocessed_No_SlidingWindow_OR_Mask/Top_Classes_Landmarks_Preprocessed_No_SlidingWindow_OR_Mask'\n",
    "\n",
    "\n",
    "Dataset= []\n",
    "Dataset_glosses = []\n",
    "\n",
    "\n",
    "for file in os.listdir(file_path_Dataset):\n",
    "    if not file.endswith(\".npy\"):\n",
    "        continue\n",
    "\n",
    "    data = np.load(os.path.join(file_path_Dataset, file))\n",
    "    label = file.split(' ')[0].lower() \n",
    "\n",
    "    Dataset.append(data)\n",
    "    Dataset_glosses.append(label)\n",
    "\n",
    "Dataset_preprocessed= []\n",
    "Dataset_preprocessed_glosses = []\n",
    "\n",
    "\n",
    "\n",
    "for file in os.listdir(file_path_Preprocessed):\n",
    "    if not file.endswith(\".npy\"):\n",
    "        continue\n",
    "\n",
    "    data = np.load(os.path.join(file_path_Preprocessed, file))\n",
    "    label = file.split('_')[0].lower()\n",
    "\n",
    "    Dataset_preprocessed.append(data)\n",
    "    Dataset_preprocessed_glosses.append(label)\n",
    "\n",
    "print(len(Dataset_preprocessed), len(Dataset_preprocessed_glosses))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d8c1bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5568 5568\n"
     ]
    }
   ],
   "source": [
    "print(len(Dataset), len(Dataset_glosses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ee58b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157, 438)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset_preprocessed[600].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d17563a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'about'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset_glosses[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37362932",
   "metadata": {},
   "source": [
    "#### Preparing the dataset For feeding to the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe21b00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_preprocessed, X_temp, y_train_preprocessed, y_temp = train_test_split(\n",
    "    Dataset_preprocessed,\n",
    "    Dataset_preprocessed_glosses,\n",
    "    test_size=0.10,   \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_val_preprocessed, X_test_preprocessed, y_val_preprocessed, y_test_preprocessed = train_test_split(\n",
    "    X_temp,\n",
    "    y_temp,\n",
    "    test_size=0.50,  \n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fd1804e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train_preprocessed = np.array(X_train_preprocessed)\n",
    "X_val_preprocessed = np.array(X_val_preprocessed)\n",
    "X_test_preprocessed = np.array(X_test_preprocessed)\n",
    "y_train_preprocessed = np.array(y_train_preprocessed)\n",
    "y_val_preprocessed = np.array(y_val_preprocessed)\n",
    "y_test_preprocessed = np.array(y_test_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79ea0fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4568, 157, 438)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_preprocessed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7813b599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "292"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(Dataset_glosses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b0afd69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(Dataset_preprocessed_glosses))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bede088",
   "metadata": {},
   "source": [
    "####  sequence-to-sequence (encoder–decoder) model with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b9aa8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, GRU, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# =========================\n",
    "# PARAMETERS\n",
    "# =========================\n",
    "T = X_train_preprocessed.shape[1]   # encoder timesteps\n",
    "D = X_train_preprocessed.shape[2]   # feature dimension\n",
    "\n",
    "ENC_UNITS = 1000\n",
    "VOCAB_SIZE = 132     # number of target words (NOT glosses)\n",
    "\n",
    "# =========================\n",
    "# ENCODER ONLY MODEL\n",
    "# =========================\n",
    "encoder_inputs = Input(shape=(T, D), name=\"encoder_inputs\")\n",
    "\n",
    "# GRU encoder (return the last state)\n",
    "encoder_output = GRU(\n",
    "    ENC_UNITS,\n",
    "    dropout=0.2\n",
    ")(encoder_inputs)  # shape: (batch_size, ENC_UNITS)\n",
    "\n",
    "# Output layer for classification\n",
    "output = Dense(\n",
    "    VOCAB_SIZE,\n",
    "    activation='softmax'\n",
    ")(encoder_output)\n",
    "\n",
    "# Build model\n",
    "model = Model(inputs=encoder_inputs, outputs=output)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "100c7851",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# Create label encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit on training labels and transform\n",
    "y_train_encoded = le.fit_transform(y_train_preprocessed)\n",
    "y_val_encoded   = le.transform(y_val_preprocessed)\n",
    "y_test_encoded  = le.transform(y_test_preprocessed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ba4b824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">157</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">438</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,320,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">132,132</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m157\u001b[0m, \u001b[38;5;34m438\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)           │     \u001b[38;5;34m4,320,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m132\u001b[0m)            │       \u001b[38;5;34m132,132\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,452,132</span> (16.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,452,132\u001b[0m (16.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,452,132</span> (16.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,452,132\u001b[0m (16.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b13260b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 859ms/step - accuracy: 0.0252 - loss: 4.8582 - val_accuracy: 0.0236 - val_loss: 4.7669\n",
      "Epoch 2/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 898ms/step - accuracy: 0.0258 - loss: 4.8133 - val_accuracy: 0.0433 - val_loss: 4.7774\n",
      "Epoch 3/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 896ms/step - accuracy: 0.0313 - loss: 4.7772 - val_accuracy: 0.0394 - val_loss: 4.7880\n",
      "Epoch 4/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 866ms/step - accuracy: 0.0302 - loss: 4.7568 - val_accuracy: 0.0354 - val_loss: 4.7630\n",
      "Epoch 5/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 846ms/step - accuracy: 0.0333 - loss: 4.7171 - val_accuracy: 0.0472 - val_loss: 4.7242\n",
      "Epoch 6/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 875ms/step - accuracy: 0.0412 - loss: 4.5225 - val_accuracy: 0.0276 - val_loss: 4.3882\n",
      "Epoch 7/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 868ms/step - accuracy: 0.0532 - loss: 4.2762 - val_accuracy: 0.0433 - val_loss: 4.2980\n",
      "Epoch 8/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 868ms/step - accuracy: 0.0729 - loss: 4.0498 - val_accuracy: 0.0630 - val_loss: 3.9530\n",
      "Epoch 9/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 875ms/step - accuracy: 0.0987 - loss: 3.7176 - val_accuracy: 0.1181 - val_loss: 3.6328\n",
      "Epoch 10/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 864ms/step - accuracy: 0.1346 - loss: 3.4423 - val_accuracy: 0.1299 - val_loss: 3.3357\n",
      "Epoch 11/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 860ms/step - accuracy: 0.1642 - loss: 3.1790 - val_accuracy: 0.1299 - val_loss: 3.1858\n",
      "Epoch 12/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 867ms/step - accuracy: 0.1966 - loss: 2.9780 - val_accuracy: 0.2165 - val_loss: 2.9411\n",
      "Epoch 13/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 843ms/step - accuracy: 0.2207 - loss: 2.8294 - val_accuracy: 0.2205 - val_loss: 2.9661\n",
      "Epoch 14/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 843ms/step - accuracy: 0.2666 - loss: 2.6562 - val_accuracy: 0.1929 - val_loss: 2.8271\n",
      "Epoch 15/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 845ms/step - accuracy: 0.3030 - loss: 2.4897 - val_accuracy: 0.2677 - val_loss: 2.6890\n",
      "Epoch 16/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 845ms/step - accuracy: 0.3459 - loss: 2.3330 - val_accuracy: 0.3150 - val_loss: 2.5504\n",
      "Epoch 17/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 837ms/step - accuracy: 0.3739 - loss: 2.1929 - val_accuracy: 0.3622 - val_loss: 2.3523\n",
      "Epoch 18/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 840ms/step - accuracy: 0.4146 - loss: 2.0259 - val_accuracy: 0.3819 - val_loss: 2.3240\n",
      "Epoch 19/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 843ms/step - accuracy: 0.4547 - loss: 1.9116 - val_accuracy: 0.3780 - val_loss: 2.2178\n",
      "Epoch 20/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 936ms/step - accuracy: 0.4877 - loss: 1.7949 - val_accuracy: 0.4252 - val_loss: 2.0967\n",
      "Epoch 21/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 886ms/step - accuracy: 0.5072 - loss: 1.6834 - val_accuracy: 0.4488 - val_loss: 2.0099\n",
      "Epoch 22/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 841ms/step - accuracy: 0.5431 - loss: 1.5860 - val_accuracy: 0.4449 - val_loss: 1.9494\n",
      "Epoch 23/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 838ms/step - accuracy: 0.5749 - loss: 1.4611 - val_accuracy: 0.4764 - val_loss: 1.9157\n",
      "Epoch 24/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 844ms/step - accuracy: 0.5915 - loss: 1.3959 - val_accuracy: 0.5039 - val_loss: 1.8942\n",
      "Epoch 25/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 846ms/step - accuracy: 0.6180 - loss: 1.2907 - val_accuracy: 0.5000 - val_loss: 1.8123\n",
      "Epoch 26/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 844ms/step - accuracy: 0.6478 - loss: 1.2315 - val_accuracy: 0.5157 - val_loss: 1.8168\n",
      "Epoch 27/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 839ms/step - accuracy: 0.6519 - loss: 1.1776 - val_accuracy: 0.5394 - val_loss: 1.7160\n",
      "Epoch 28/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 847ms/step - accuracy: 0.6714 - loss: 1.0994 - val_accuracy: 0.5354 - val_loss: 1.7391\n",
      "Epoch 29/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 830ms/step - accuracy: 0.6896 - loss: 1.0481 - val_accuracy: 0.5591 - val_loss: 1.7026\n",
      "Epoch 30/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 925ms/step - accuracy: 0.6983 - loss: 1.0056 - val_accuracy: 0.5709 - val_loss: 1.6587\n",
      "Epoch 31/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 898ms/step - accuracy: 0.7277 - loss: 0.9408 - val_accuracy: 0.5354 - val_loss: 1.6651\n",
      "Epoch 32/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 906ms/step - accuracy: 0.7281 - loss: 0.9030 - val_accuracy: 0.5472 - val_loss: 1.6787\n",
      "Epoch 33/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 927ms/step - accuracy: 0.7557 - loss: 0.8398 - val_accuracy: 0.5906 - val_loss: 1.6140\n",
      "Epoch 34/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 909ms/step - accuracy: 0.7715 - loss: 0.7862 - val_accuracy: 0.5630 - val_loss: 1.6266\n",
      "Epoch 35/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 906ms/step - accuracy: 0.7831 - loss: 0.7399 - val_accuracy: 0.5827 - val_loss: 1.5564\n",
      "Epoch 36/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 907ms/step - accuracy: 0.7894 - loss: 0.7193 - val_accuracy: 0.5945 - val_loss: 1.5601\n",
      "Epoch 37/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 931ms/step - accuracy: 0.7960 - loss: 0.6897 - val_accuracy: 0.5630 - val_loss: 1.5795\n",
      "Epoch 38/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 922ms/step - accuracy: 0.8159 - loss: 0.6462 - val_accuracy: 0.5866 - val_loss: 1.5017\n",
      "Epoch 39/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 958ms/step - accuracy: 0.8277 - loss: 0.6027 - val_accuracy: 0.5827 - val_loss: 1.5144\n",
      "Epoch 40/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 921ms/step - accuracy: 0.8277 - loss: 0.5800 - val_accuracy: 0.6024 - val_loss: 1.6272\n",
      "Epoch 41/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 925ms/step - accuracy: 0.8457 - loss: 0.5303 - val_accuracy: 0.5906 - val_loss: 1.5405\n",
      "Epoch 42/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 921ms/step - accuracy: 0.8450 - loss: 0.5274 - val_accuracy: 0.5984 - val_loss: 1.5128\n",
      "Epoch 43/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 944ms/step - accuracy: 0.8496 - loss: 0.5187 - val_accuracy: 0.5906 - val_loss: 1.5780\n",
      "Epoch 44/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 917ms/step - accuracy: 0.8570 - loss: 0.4910 - val_accuracy: 0.6102 - val_loss: 1.4926\n",
      "Epoch 45/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 979ms/step - accuracy: 0.8746 - loss: 0.4408 - val_accuracy: 0.5866 - val_loss: 1.5107\n",
      "Epoch 46/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 950ms/step - accuracy: 0.8746 - loss: 0.4327 - val_accuracy: 0.5984 - val_loss: 1.5652\n",
      "Epoch 47/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 969ms/step - accuracy: 0.8768 - loss: 0.4121 - val_accuracy: 0.6063 - val_loss: 1.6056\n",
      "Epoch 48/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 896ms/step - accuracy: 0.8816 - loss: 0.3979 - val_accuracy: 0.5827 - val_loss: 1.6197\n",
      "Epoch 49/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 901ms/step - accuracy: 0.8956 - loss: 0.3822 - val_accuracy: 0.6102 - val_loss: 1.5724\n",
      "Epoch 50/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 894ms/step - accuracy: 0.9081 - loss: 0.3361 - val_accuracy: 0.5827 - val_loss: 1.6026\n",
      "Epoch 51/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 889ms/step - accuracy: 0.8949 - loss: 0.3643 - val_accuracy: 0.5984 - val_loss: 1.5982\n",
      "Epoch 52/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 911ms/step - accuracy: 0.9039 - loss: 0.3263 - val_accuracy: 0.5906 - val_loss: 1.5618\n",
      "Epoch 53/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 909ms/step - accuracy: 0.9173 - loss: 0.2927 - val_accuracy: 0.5906 - val_loss: 1.6346\n",
      "Epoch 54/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 853ms/step - accuracy: 0.9056 - loss: 0.3225 - val_accuracy: 0.6063 - val_loss: 1.6217\n",
      "Epoch 55/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 847ms/step - accuracy: 0.9087 - loss: 0.3068 - val_accuracy: 0.6260 - val_loss: 1.5928\n",
      "Epoch 56/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 860ms/step - accuracy: 0.9260 - loss: 0.2748 - val_accuracy: 0.6378 - val_loss: 1.5292\n",
      "Epoch 57/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 868ms/step - accuracy: 0.9225 - loss: 0.2706 - val_accuracy: 0.5866 - val_loss: 1.6671\n",
      "Epoch 58/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 853ms/step - accuracy: 0.9308 - loss: 0.2407 - val_accuracy: 0.6142 - val_loss: 1.6046\n",
      "Epoch 59/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 856ms/step - accuracy: 0.9409 - loss: 0.2244 - val_accuracy: 0.6181 - val_loss: 1.6531\n",
      "Epoch 60/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 857ms/step - accuracy: 0.9383 - loss: 0.2281 - val_accuracy: 0.6024 - val_loss: 1.5224\n",
      "Epoch 61/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 853ms/step - accuracy: 0.9249 - loss: 0.2627 - val_accuracy: 0.6220 - val_loss: 1.6155\n",
      "Epoch 62/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 849ms/step - accuracy: 0.9446 - loss: 0.2104 - val_accuracy: 0.5984 - val_loss: 1.6196\n",
      "Epoch 63/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 854ms/step - accuracy: 0.9387 - loss: 0.2202 - val_accuracy: 0.6181 - val_loss: 1.6182\n",
      "Epoch 64/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 850ms/step - accuracy: 0.9442 - loss: 0.2067 - val_accuracy: 0.6299 - val_loss: 1.5104\n",
      "Epoch 65/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 851ms/step - accuracy: 0.9385 - loss: 0.2136 - val_accuracy: 0.6299 - val_loss: 1.6104\n",
      "Epoch 66/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 859ms/step - accuracy: 0.9488 - loss: 0.2052 - val_accuracy: 0.6063 - val_loss: 1.7345\n",
      "Epoch 67/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 848ms/step - accuracy: 0.9479 - loss: 0.1867 - val_accuracy: 0.6417 - val_loss: 1.5934\n",
      "Epoch 68/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 848ms/step - accuracy: 0.9483 - loss: 0.1856 - val_accuracy: 0.6181 - val_loss: 1.7238\n",
      "Epoch 69/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 856ms/step - accuracy: 0.9468 - loss: 0.1910 - val_accuracy: 0.6299 - val_loss: 1.6473\n",
      "Epoch 70/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 858ms/step - accuracy: 0.9573 - loss: 0.1700 - val_accuracy: 0.6339 - val_loss: 1.7592\n",
      "Epoch 71/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 915ms/step - accuracy: 0.9453 - loss: 0.1899 - val_accuracy: 0.6063 - val_loss: 1.6659\n",
      "Epoch 72/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 870ms/step - accuracy: 0.9536 - loss: 0.1685 - val_accuracy: 0.6299 - val_loss: 1.7143\n",
      "Epoch 73/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 854ms/step - accuracy: 0.9486 - loss: 0.1809 - val_accuracy: 0.6102 - val_loss: 1.6953\n",
      "Epoch 74/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 855ms/step - accuracy: 0.9615 - loss: 0.1492 - val_accuracy: 0.6102 - val_loss: 1.6714\n",
      "Epoch 75/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 865ms/step - accuracy: 0.9567 - loss: 0.1613 - val_accuracy: 0.5866 - val_loss: 1.7728\n",
      "Epoch 76/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 857ms/step - accuracy: 0.9562 - loss: 0.1587 - val_accuracy: 0.6063 - val_loss: 1.7081\n",
      "Epoch 77/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 849ms/step - accuracy: 0.9630 - loss: 0.1428 - val_accuracy: 0.6181 - val_loss: 1.7059\n",
      "Epoch 78/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 854ms/step - accuracy: 0.9665 - loss: 0.1256 - val_accuracy: 0.6378 - val_loss: 1.6651\n",
      "Epoch 79/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 854ms/step - accuracy: 0.9658 - loss: 0.1264 - val_accuracy: 0.6024 - val_loss: 1.7602\n",
      "Epoch 80/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 852ms/step - accuracy: 0.9630 - loss: 0.1353 - val_accuracy: 0.5866 - val_loss: 1.8926\n",
      "Epoch 81/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 867ms/step - accuracy: 0.9665 - loss: 0.1314 - val_accuracy: 0.5984 - val_loss: 1.7473\n",
      "Epoch 82/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 865ms/step - accuracy: 0.9630 - loss: 0.1412 - val_accuracy: 0.6181 - val_loss: 1.7413\n",
      "Epoch 83/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 856ms/step - accuracy: 0.9637 - loss: 0.1372 - val_accuracy: 0.6142 - val_loss: 1.8559\n",
      "Epoch 84/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 858ms/step - accuracy: 0.9556 - loss: 0.1643 - val_accuracy: 0.6063 - val_loss: 1.7062\n",
      "Epoch 85/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 870ms/step - accuracy: 0.9573 - loss: 0.1388 - val_accuracy: 0.5866 - val_loss: 1.7252\n",
      "Epoch 86/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 856ms/step - accuracy: 0.9709 - loss: 0.1169 - val_accuracy: 0.6220 - val_loss: 1.7612\n",
      "Epoch 87/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 853ms/step - accuracy: 0.9709 - loss: 0.1122 - val_accuracy: 0.6063 - val_loss: 1.8453\n",
      "Epoch 88/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 853ms/step - accuracy: 0.9665 - loss: 0.1188 - val_accuracy: 0.6299 - val_loss: 1.7776\n",
      "Epoch 89/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 852ms/step - accuracy: 0.9571 - loss: 0.1513 - val_accuracy: 0.6063 - val_loss: 1.8079\n",
      "Epoch 90/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 858ms/step - accuracy: 0.9720 - loss: 0.1137 - val_accuracy: 0.6024 - val_loss: 1.7947\n",
      "Epoch 91/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 850ms/step - accuracy: 0.9735 - loss: 0.1016 - val_accuracy: 0.6063 - val_loss: 1.8971\n",
      "Epoch 92/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 852ms/step - accuracy: 0.9709 - loss: 0.1086 - val_accuracy: 0.6220 - val_loss: 1.6410\n",
      "Epoch 93/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 848ms/step - accuracy: 0.9700 - loss: 0.1056 - val_accuracy: 0.6063 - val_loss: 1.8465\n",
      "Epoch 94/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 851ms/step - accuracy: 0.9735 - loss: 0.1017 - val_accuracy: 0.6378 - val_loss: 1.8355\n",
      "Epoch 95/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 869ms/step - accuracy: 0.9722 - loss: 0.1024 - val_accuracy: 0.5906 - val_loss: 1.8350\n",
      "Epoch 96/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 856ms/step - accuracy: 0.9731 - loss: 0.0983 - val_accuracy: 0.6299 - val_loss: 1.7618\n",
      "Epoch 97/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 854ms/step - accuracy: 0.9753 - loss: 0.0973 - val_accuracy: 0.6299 - val_loss: 1.7725\n",
      "Epoch 98/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 863ms/step - accuracy: 0.9739 - loss: 0.0929 - val_accuracy: 0.6102 - val_loss: 1.8282\n",
      "Epoch 99/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 856ms/step - accuracy: 0.9685 - loss: 0.1126 - val_accuracy: 0.5984 - val_loss: 1.7973\n",
      "Epoch 100/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 864ms/step - accuracy: 0.9783 - loss: 0.0850 - val_accuracy: 0.6102 - val_loss: 1.6781\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_preprocessed,      # encoder input\n",
    "    y_train_encoded,           # target word labels\n",
    "    validation_data=(X_val_preprocessed, y_val_encoded),\n",
    "    batch_size=32,\n",
    "    epochs=100\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4dbd46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - accuracy: 0.5906 - loss: 1.8193\n",
      "Test accuracy: 0.5905511975288391\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test_preprocessed, y_test_encoded)\n",
    "print(\"Test accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99daa11",
   "metadata": {},
   "source": [
    "### Before preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "50031cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original samples: 5568\n",
      "Original vocab size: 292\n",
      "Filtered samples: 5422\n",
      "Filtered vocab size: 146\n"
     ]
    }
   ],
   "source": [
    "# Count how many samples per word\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "label_counts = Counter(Dataset_glosses)\n",
    "\n",
    "MIN_SAMPLES = 2  # must be >=2 for stratification\n",
    "\n",
    "valid_labels = {\n",
    "    label for label, count in label_counts.items()\n",
    "    if count >= MIN_SAMPLES\n",
    "}\n",
    "\n",
    "print(\"Original samples:\", len(Dataset))\n",
    "print(\"Original vocab size:\", len(label_counts))\n",
    "\n",
    "# Filter dataset\n",
    "Dataset_filtered = []\n",
    "Glosses_filtered = []\n",
    "\n",
    "for x, y in zip(Dataset, Dataset_glosses):\n",
    "    if y in valid_labels:\n",
    "        Dataset_filtered.append(x)\n",
    "        Glosses_filtered.append(y)\n",
    "\n",
    "print(\"Filtered samples:\", len(Dataset_filtered))\n",
    "print(\"Filtered vocab size:\", len(set(Glosses_filtered)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "102fce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw, X_temp, y_train_raw, y_temp = train_test_split(\n",
    "    Dataset_filtered,\n",
    "    Glosses_filtered,\n",
    "    test_size=0.10,\n",
    "    random_state=42,\n",
    "    stratify=Glosses_filtered\n",
    ")\n",
    "\n",
    "X_val_raw, X_test_raw, y_val_raw, y_test_raw = train_test_split(\n",
    "    X_temp,\n",
    "    y_temp,\n",
    "    test_size=0.50,\n",
    "    random_state=42,\n",
    "    stratify=y_temp\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "49428353",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 64\n",
    "\n",
    "def pad_or_truncate(sequence, max_len=64):\n",
    "    T, D = sequence.shape\n",
    "    if T > max_len:\n",
    "        return sequence[:max_len]\n",
    "    elif T < max_len:\n",
    "        padding = np.zeros((max_len - T, D))\n",
    "        return np.vstack([sequence, padding])\n",
    "    return sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fce4364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (4879, 64, 438)\n",
      "X_val shape: (271, 64, 438)\n",
      "X_test shape: (272, 64, 438)\n"
     ]
    }
   ],
   "source": [
    "X_train_raw = np.array([pad_or_truncate(seq, MAX_LEN) for seq in X_train_raw])\n",
    "X_val_raw   = np.array([pad_or_truncate(seq, MAX_LEN) for seq in X_val_raw])\n",
    "X_test_raw  = np.array([pad_or_truncate(seq, MAX_LEN) for seq in X_test_raw])\n",
    "\n",
    "print(\"X_train shape:\", X_train_raw.shape)  # (N, 64, D)\n",
    "print(\"X_val shape:\", X_val_raw.shape)  # (N, 64, D)\n",
    "print(\"X_test shape:\", X_test_raw.shape)  # (N, 64, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "628c13db",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "y_train = le.fit_transform(y_train_raw)\n",
    "y_val   = le.transform(y_val_raw)\n",
    "y_test  = le.transform(y_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9239dd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# =========================\n",
    "# PARAMETERS\n",
    "# =========================\n",
    "T = X_train_raw.shape[1]   # encoder timesteps\n",
    "D = X_train_raw.shape[2]   # feature dimension\n",
    "\n",
    "ENC_UNITS = 1000\n",
    "VOCAB_SIZE = 146    # number of target words (NOT glosses)\n",
    "\n",
    "# =========================\n",
    "# ENCODER ONLY MODEL\n",
    "# =========================\n",
    "encoder_inputs = Input(shape=(T, D), name=\"encoder_inputs\")\n",
    "\n",
    "# GRU encoder (return the last state)\n",
    "encoder_output = GRU(\n",
    "    ENC_UNITS,\n",
    "    dropout=0.2\n",
    ")(encoder_inputs)  # shape: (batch_size, ENC_UNITS)\n",
    "\n",
    "# Output layer for classification\n",
    "output = Dense(\n",
    "    VOCAB_SIZE,\n",
    "    activation='softmax'\n",
    ")(encoder_output)\n",
    "\n",
    "# Build model\n",
    "model_raw = Model(inputs=encoder_inputs, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "27763a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_16\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_16\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">157</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">438</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,320,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">132,132</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m157\u001b[0m, \u001b[38;5;34m438\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_16 (\u001b[38;5;33mGRU\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)           │     \u001b[38;5;34m4,320,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m132\u001b[0m)            │       \u001b[38;5;34m132,132\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,452,132</span> (16.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,452,132\u001b[0m (16.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,452,132</span> (16.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,452,132\u001b[0m (16.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_raw.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "20fe556c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 385ms/step - accuracy: 0.0172 - loss: 4.9813 - val_accuracy: 0.0258 - val_loss: 4.9330\n",
      "Epoch 2/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 375ms/step - accuracy: 0.0258 - loss: 4.9226 - val_accuracy: 0.0332 - val_loss: 4.9306\n",
      "Epoch 3/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 361ms/step - accuracy: 0.0324 - loss: 4.8085 - val_accuracy: 0.0221 - val_loss: 4.7359\n",
      "Epoch 4/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 366ms/step - accuracy: 0.0437 - loss: 4.5540 - val_accuracy: 0.0443 - val_loss: 4.5475\n",
      "Epoch 5/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 374ms/step - accuracy: 0.0432 - loss: 4.4424 - val_accuracy: 0.0517 - val_loss: 4.3821\n",
      "Epoch 6/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 369ms/step - accuracy: 0.0547 - loss: 4.3173 - val_accuracy: 0.0554 - val_loss: 4.2814\n",
      "Epoch 7/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 364ms/step - accuracy: 0.0549 - loss: 4.2020 - val_accuracy: 0.0590 - val_loss: 4.1903\n",
      "Epoch 8/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 380ms/step - accuracy: 0.0642 - loss: 4.1096 - val_accuracy: 0.0701 - val_loss: 4.1407\n",
      "Epoch 9/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 365ms/step - accuracy: 0.0791 - loss: 3.9941 - val_accuracy: 0.0812 - val_loss: 3.9316\n",
      "Epoch 10/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 367ms/step - accuracy: 0.0947 - loss: 3.8653 - val_accuracy: 0.0923 - val_loss: 3.9602\n",
      "Epoch 11/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.1064 - loss: 3.7371 - val_accuracy: 0.1218 - val_loss: 3.7001\n",
      "Epoch 12/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 378ms/step - accuracy: 0.1277 - loss: 3.5908 - val_accuracy: 0.1402 - val_loss: 3.5529\n",
      "Epoch 13/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 379ms/step - accuracy: 0.1357 - loss: 3.4946 - val_accuracy: 0.1255 - val_loss: 3.4701\n",
      "Epoch 14/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 359ms/step - accuracy: 0.1570 - loss: 3.3811 - val_accuracy: 0.1402 - val_loss: 3.3307\n",
      "Epoch 15/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 364ms/step - accuracy: 0.1627 - loss: 3.2924 - val_accuracy: 0.1882 - val_loss: 3.3046\n",
      "Epoch 16/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 361ms/step - accuracy: 0.1834 - loss: 3.2088 - val_accuracy: 0.1661 - val_loss: 3.2847\n",
      "Epoch 17/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 361ms/step - accuracy: 0.1998 - loss: 3.1325 - val_accuracy: 0.1771 - val_loss: 3.2023\n",
      "Epoch 18/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 361ms/step - accuracy: 0.2089 - loss: 3.0670 - val_accuracy: 0.2030 - val_loss: 3.1584\n",
      "Epoch 19/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 366ms/step - accuracy: 0.2404 - loss: 2.9608 - val_accuracy: 0.2066 - val_loss: 3.1127\n",
      "Epoch 20/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 358ms/step - accuracy: 0.2488 - loss: 2.8907 - val_accuracy: 0.2362 - val_loss: 3.0168\n",
      "Epoch 21/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 366ms/step - accuracy: 0.2640 - loss: 2.8418 - val_accuracy: 0.2177 - val_loss: 3.0055\n",
      "Epoch 22/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 360ms/step - accuracy: 0.2740 - loss: 2.7589 - val_accuracy: 0.2472 - val_loss: 2.9830\n",
      "Epoch 23/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 358ms/step - accuracy: 0.2884 - loss: 2.6773 - val_accuracy: 0.2546 - val_loss: 2.8560\n",
      "Epoch 24/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 358ms/step - accuracy: 0.3023 - loss: 2.5859 - val_accuracy: 0.2288 - val_loss: 2.8553\n",
      "Epoch 25/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 360ms/step - accuracy: 0.3257 - loss: 2.5143 - val_accuracy: 0.2694 - val_loss: 2.7516\n",
      "Epoch 26/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 363ms/step - accuracy: 0.3439 - loss: 2.4550 - val_accuracy: 0.2878 - val_loss: 2.7261\n",
      "Epoch 27/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 365ms/step - accuracy: 0.3575 - loss: 2.3791 - val_accuracy: 0.2952 - val_loss: 2.7888\n",
      "Epoch 28/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 357ms/step - accuracy: 0.3841 - loss: 2.2848 - val_accuracy: 0.3063 - val_loss: 2.6236\n",
      "Epoch 29/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 358ms/step - accuracy: 0.4013 - loss: 2.2390 - val_accuracy: 0.3395 - val_loss: 2.5740\n",
      "Epoch 30/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 360ms/step - accuracy: 0.4255 - loss: 2.1498 - val_accuracy: 0.2878 - val_loss: 2.6174\n",
      "Epoch 31/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 365ms/step - accuracy: 0.4261 - loss: 2.1147 - val_accuracy: 0.3100 - val_loss: 2.5568\n",
      "Epoch 32/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 365ms/step - accuracy: 0.4423 - loss: 2.0560 - val_accuracy: 0.3247 - val_loss: 2.5936\n",
      "Epoch 33/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 359ms/step - accuracy: 0.4552 - loss: 1.9934 - val_accuracy: 0.3542 - val_loss: 2.5054\n",
      "Epoch 34/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 365ms/step - accuracy: 0.4653 - loss: 1.9469 - val_accuracy: 0.3432 - val_loss: 2.4920\n",
      "Epoch 35/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 361ms/step - accuracy: 0.4782 - loss: 1.8876 - val_accuracy: 0.3321 - val_loss: 2.4728\n",
      "Epoch 36/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 360ms/step - accuracy: 0.4966 - loss: 1.8353 - val_accuracy: 0.3579 - val_loss: 2.4210\n",
      "Epoch 37/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 359ms/step - accuracy: 0.4972 - loss: 1.7919 - val_accuracy: 0.3727 - val_loss: 2.3820\n",
      "Epoch 38/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 359ms/step - accuracy: 0.5173 - loss: 1.7110 - val_accuracy: 0.3653 - val_loss: 2.3714\n",
      "Epoch 39/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 361ms/step - accuracy: 0.5386 - loss: 1.6751 - val_accuracy: 0.3727 - val_loss: 2.3822\n",
      "Epoch 40/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 353ms/step - accuracy: 0.5581 - loss: 1.6027 - val_accuracy: 0.3653 - val_loss: 2.4004\n",
      "Epoch 41/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 357ms/step - accuracy: 0.5550 - loss: 1.5787 - val_accuracy: 0.3948 - val_loss: 2.3379\n",
      "Epoch 42/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 360ms/step - accuracy: 0.5745 - loss: 1.5339 - val_accuracy: 0.4022 - val_loss: 2.2712\n",
      "Epoch 43/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 360ms/step - accuracy: 0.5929 - loss: 1.4775 - val_accuracy: 0.3838 - val_loss: 2.2616\n",
      "Epoch 44/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 359ms/step - accuracy: 0.6018 - loss: 1.4470 - val_accuracy: 0.3764 - val_loss: 2.3012\n",
      "Epoch 45/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 361ms/step - accuracy: 0.6167 - loss: 1.3882 - val_accuracy: 0.3875 - val_loss: 2.2997\n",
      "Epoch 46/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 354ms/step - accuracy: 0.6255 - loss: 1.3511 - val_accuracy: 0.3690 - val_loss: 2.3830\n",
      "Epoch 47/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 359ms/step - accuracy: 0.6276 - loss: 1.3270 - val_accuracy: 0.3690 - val_loss: 2.4034\n",
      "Epoch 48/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 363ms/step - accuracy: 0.6358 - loss: 1.3087 - val_accuracy: 0.3985 - val_loss: 2.2717\n",
      "Epoch 49/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 362ms/step - accuracy: 0.6575 - loss: 1.2499 - val_accuracy: 0.4096 - val_loss: 2.3526\n",
      "Epoch 50/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 375ms/step - accuracy: 0.6639 - loss: 1.2241 - val_accuracy: 0.3838 - val_loss: 2.3456\n"
     ]
    }
   ],
   "source": [
    "history = model_raw.fit(\n",
    "    X_train_raw,      # encoder input\n",
    "    y_train,           # target word labels\n",
    "    validation_data=(X_val_raw, y_val),\n",
    "    batch_size=32,\n",
    "    epochs=50\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6f4b55e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.4706 - loss: 2.1804\n",
      "Test accuracy: 0.47058823704719543\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model_raw.evaluate(X_test_raw, y_test)\n",
    "print(\"Test accuracy:\", test_acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sign_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
