---
# **AI-Powered Sign Language Translation Project**

Welcome! ğŸ‘‹ This repository contains a **modular framework for Sign Language Translation** (Sign â†’ Text and Text â†’ Sign) using **landmarks and deep learning models**. Currently, we have a **TCN model**, but you can easily add new models like Transformers or LSTMs.

---

## **ğŸ“‚ Project Structure**

```
AI/
â”œâ”€ src/
â”‚  â”œâ”€ configs/                   # Model hyperparameters
â”‚  â”‚  â”œâ”€ tcn_config.py           # TCN-specific config
â”‚  â”‚  â””â”€ transformer_config.py   # Example template for new models
â”‚  â”œâ”€ data/
â”‚  â”‚  â”œâ”€ dataloaders.py          # Prepares PyTorch DataLoaders
â”‚  â”‚  â””â”€ preprocessing/          # Landmark extraction & preprocessing scripts
â”‚  â”œâ”€ models/
â”‚  â”‚  â””â”€ sign2text/
â”‚  â”‚     â”œâ”€ tcn.py               # TCN model
â”‚  â”‚     â”œâ”€ losses.py            # Loss functions (e.g., SmoothCE)
â”‚  â”‚     â””â”€ transformer.py       # Example template for a new model
â”‚  â”œâ”€ training/
â”‚  â”‚  â”œâ”€ train_tcn.py            # TCN training script
â”‚  â”‚  â”œâ”€ train_transformer.py    # Example template for new models
â”‚  â”‚  â””â”€ trainer.py              # Generic training utilities (run_epoch, etc.)
â”‚  â””â”€ evaluation/
â”‚     â”œâ”€ eval_tcn.py             # TCN evaluation, metrics, confusion, save plots
â”‚     â””â”€ eval_transformer.py     # Example template for new models
â”œâ”€ experiments/
â”‚  â””â”€ plots/                     # Saved metrics, confusion matrices, model structures
â”œâ”€ requirements.txt               # Python dependencies
â””â”€ README.md
```

---

## **ğŸ“¦ Environment Setup**

1. Clone the repo:

```bash
git clone <repo-url>
cd AI/
```

2. Create a virtual environment:

```bash
python -m venv venv
```

3. Activate the environment:

```bash
# Windows
venv\Scripts\activate
# macOS/Linux
source venv/bin/activate
```

4. Install dependencies:

```bash
pip install -r requirements.txt
```

---

## **ğŸ—‚ï¸ Data Preparation**

* Place **landmark `.npy` files** in a folder (e.g., `Top_Classes_Landmarks_Preprocessed`)
* Preprocessing scripts are in: `src/data/preprocessing/`
* Data loaders are handled in `src/data/dataloaders.py`. Just call:

```python
from src.data.dataloaders import build_dataloaders
train_loader, val_loader, test_loader, num_classes = build_dataloaders()
```

---

## **âš¡ Training a Model**

### **TCN Model (default)**

```bash
python -m src.training.train_tcn
```

* Saves checkpoints, best model, metrics automatically.
* Checkpoints: `MODEL_SAVE_PATH` defined in `tcn_config.py`

---

### **Adding a New Model (e.g., Transformer)**

1. **Create a model file**

```text
src/models/sign2text/transformer.py
```

* Implement a class like:

```python
class TransformerModel(nn.Module):
    def __init__(self, input_dim, num_classes):
        super().__init__()
        ...
    def forward(self, x, mask):
        ...
        return out
```

2. **Create a config file**

```text
src/configs/transformer_config.py
```

* Define hyperparameters: `LR`, `BATCH_SIZE`, `EPOCHS`, `DEVICE`, `MODEL_SAVE_PATH`, etc.

3. **Create a training script**

```text
src/training/train_transformer.py
```

* Import your model and config
* Reuse: `build_dataloaders()`, `SmoothCE`, `run_epoch()`
* Run training:

```bash
python -m src.training.train_transformer
```

4. **Create an evaluation script**

```text
src/evaluation/eval_transformer.py
```

* Import your model and config
* Copy `eval_tcn.py` logic
* Replace TCN references â†’ your model
* Use a `_transformer` suffix for saved metrics and plots
* Run evaluation:

```bash
python -m src.evaluation.eval_transformer
```

---

## **ğŸ›  Reusable Components**

* **Data loaders** â†’ `build_dataloaders()`
* **Loss function** â†’ `SmoothCE`
* **Training loop** â†’ `run_epoch()`
* **Evaluation utilities** â†’ confusion matrix, metrics, plots

> You only need to implement the **model** and **its config**, everything else is reusable.

---

## **ğŸ“Š Outputs**

For each model, the following are automatically saved:

* `experiments/plots/test_metrics_<model>.json` â†’ evaluation metrics
* `experiments/plots/confusion_matrix_<model>.png` â†’ confusion matrix
* `experiments/plots/model_structure_<model>.txt` â†’ model structure

> Replace `<model>` with `_tcn`, `_transformer`, etc.

---

## **ğŸ’¡ Tips**

* Always give each model **unique checkpoint and plot filenames**.
* Keep configs separate per model for clarity.
* Later, you can merge training/eval scripts into **generic scripts** for multiple models.

---
Perfect, Mariam ğŸ˜ â€” hereâ€™s a simple **diagram you can add to the README** showing what your friends need to **create vs reuse** when adding a new model. You can place it under a section like **â€œAdding a New Modelâ€**.

---

## **ğŸ–¼ï¸ Visual Guide: Adding a New Model**

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Create for new model     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ src/models/sign2text/<model>.py   <- Your model class
â”‚ src/configs/<model>_config.py     <- Hyperparameters & paths
â”‚ src/training/train_<model>.py     <- Training script
â”‚ src/evaluation/eval_<model>.py    <- Evaluation script
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

           â¬‡ Reuse existing components

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Reusable             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ src/data/dataloaders.py       <- Data loaders
â”‚ src/models/losses.py          <- SmoothCE and other losses
â”‚ src/training/trainer.py       <- run_epoch(), gradient clipping, etc.
â”‚ src/data/preprocessing/       <- Landmark extraction, sliding window
â”‚ src/evaluation/utils.py       <- Confusion, metrics, plotting
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

**How it works:**

1. **Create** files for your new model, config, training, and evaluation.
2. **Reuse** everything else: data loaders, loss, training utilities, and evaluation helpers.
3. **Run training & evaluation** using your new scripts.
4. **Outputs** are automatically saved in `experiments/plots/` with a model-specific suffix.

---
