{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f6bcb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import mediapipe as mp \n",
    "import cv2 as cv\n",
    "import os \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbc09c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5076 5076\n"
     ]
    }
   ],
   "source": [
    "## let's load the extracted landmarks \n",
    "\n",
    "file_path_Dataset='Top_Classes_Landmarks/Top_Classes_Landmarks'\n",
    "file_path_Preprocessed='Top_Classes_Landmarks_Preprocessed_No_SlidingWindow_OR_Mask/Top_Classes_Landmarks_Preprocessed_No_SlidingWindow_OR_Mask'\n",
    "\n",
    "\n",
    "Dataset= []\n",
    "Dataset_glosses = []\n",
    "\n",
    "\n",
    "for file in os.listdir(file_path_Dataset):\n",
    "    if not file.endswith(\".npy\"):\n",
    "        continue\n",
    "\n",
    "    data = np.load(os.path.join(file_path_Dataset, file))\n",
    "    label = file.split(' ')[0].lower() \n",
    "\n",
    "    Dataset.append(data)\n",
    "    Dataset_glosses.append(label)\n",
    "\n",
    "Dataset_preprocessed= []\n",
    "Dataset_preprocessed_glosses = []\n",
    "\n",
    "\n",
    "\n",
    "for file in os.listdir(file_path_Preprocessed):\n",
    "    if not file.endswith(\".npy\"):\n",
    "        continue\n",
    "\n",
    "    data = np.load(os.path.join(file_path_Preprocessed, file))\n",
    "    label = file.split('_')[0].lower()\n",
    "\n",
    "    Dataset_preprocessed.append(data)\n",
    "    Dataset_preprocessed_glosses.append(label)\n",
    "\n",
    "print(len(Dataset_preprocessed), len(Dataset_preprocessed_glosses))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d8c1bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5568 5568\n"
     ]
    }
   ],
   "source": [
    "print(len(Dataset), len(Dataset_glosses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ee58b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157, 438)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset_preprocessed[600].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d17563a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'about'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset_glosses[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37362932",
   "metadata": {},
   "source": [
    "#### Preparing the dataset For feeding to the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe21b00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_preprocessed, X_temp, y_train_preprocessed, y_temp = train_test_split(\n",
    "    Dataset_preprocessed,\n",
    "    Dataset_preprocessed_glosses,\n",
    "    test_size=0.10,   \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_val_preprocessed, X_test_preprocessed, y_val_preprocessed, y_test_preprocessed = train_test_split(\n",
    "    X_temp,\n",
    "    y_temp,\n",
    "    test_size=0.50,  \n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fd1804e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train_preprocessed = np.array(X_train_preprocessed)\n",
    "X_val_preprocessed = np.array(X_val_preprocessed)\n",
    "X_test_preprocessed = np.array(X_test_preprocessed)\n",
    "y_train_preprocessed = np.array(y_train_preprocessed)\n",
    "y_val_preprocessed = np.array(y_val_preprocessed)\n",
    "y_test_preprocessed = np.array(y_test_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79ea0fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4568, 157, 438)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_preprocessed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7813b599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "292"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(Dataset_glosses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b0afd69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(Dataset_preprocessed_glosses))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bede088",
   "metadata": {},
   "source": [
    "####  sequence-to-sequence (encoder–decoder) model with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9aa8c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_12\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_12\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">157</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">438</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,320,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">132,132</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m157\u001b[0m, \u001b[38;5;34m438\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_12 (\u001b[38;5;33mGRU\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)           │     \u001b[38;5;34m4,320,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m132\u001b[0m)            │       \u001b[38;5;34m132,132\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,452,132</span> (16.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,452,132\u001b[0m (16.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,452,132</span> (16.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,452,132\u001b[0m (16.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, GRU, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# =========================\n",
    "# PARAMETERS\n",
    "# =========================\n",
    "T = X_train_preprocessed.shape[1]   # encoder timesteps\n",
    "D = X_train_preprocessed.shape[2]   # feature dimension\n",
    "\n",
    "ENC_UNITS = 1000\n",
    "VOCAB_SIZE = 132     # number of target words (NOT glosses)\n",
    "\n",
    "# =========================\n",
    "# ENCODER ONLY MODEL\n",
    "# =========================\n",
    "encoder_inputs = Input(shape=(T, D), name=\"encoder_inputs\")\n",
    "\n",
    "# GRU encoder (return the last state)\n",
    "encoder_output = GRU(\n",
    "    ENC_UNITS,\n",
    "    dropout=0.2\n",
    ")(encoder_inputs)  # shape: (batch_size, ENC_UNITS)\n",
    "\n",
    "# Output layer for classification\n",
    "output = Dense(\n",
    "    VOCAB_SIZE,\n",
    "    activation='softmax'\n",
    ")(encoder_output)\n",
    "\n",
    "# Build model\n",
    "model = Model(inputs=encoder_inputs, outputs=output)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "100c7851",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shahd\\miniconda3\\envs\\sign_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\shahd\\miniconda3\\envs\\sign_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:129: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\shahd\\miniconda3\\envs\\sign_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:129: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# Create label encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit on training labels and transform\n",
    "y_train_encoded = le.fit_transform(y_train_preprocessed)\n",
    "y_val_encoded   = le.transform(y_val_preprocessed)\n",
    "y_test_encoded  = le.transform(y_test_preprocessed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2ba4b824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_12\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_12\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">157</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">438</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,320,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">132,132</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m157\u001b[0m, \u001b[38;5;34m438\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_12 (\u001b[38;5;33mGRU\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)           │     \u001b[38;5;34m4,320,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m132\u001b[0m)            │       \u001b[38;5;34m132,132\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,452,132</span> (16.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,452,132\u001b[0m (16.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,452,132</span> (16.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,452,132\u001b[0m (16.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4b13260b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 850ms/step - accuracy: 0.0204 - loss: 4.8749 - val_accuracy: 0.0276 - val_loss: 4.7760\n",
      "Epoch 2/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 911ms/step - accuracy: 0.0263 - loss: 4.8142 - val_accuracy: 0.0276 - val_loss: 4.7841\n",
      "Epoch 3/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 906ms/step - accuracy: 0.0278 - loss: 4.7848 - val_accuracy: 0.0354 - val_loss: 4.8008\n",
      "Epoch 4/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 884ms/step - accuracy: 0.0296 - loss: 4.7565 - val_accuracy: 0.0472 - val_loss: 4.7681\n",
      "Epoch 5/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 899ms/step - accuracy: 0.0337 - loss: 4.7331 - val_accuracy: 0.0472 - val_loss: 4.7517\n",
      "Epoch 6/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 912ms/step - accuracy: 0.0355 - loss: 4.6990 - val_accuracy: 0.0236 - val_loss: 4.7428\n",
      "Epoch 7/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 921ms/step - accuracy: 0.0418 - loss: 4.5428 - val_accuracy: 0.0630 - val_loss: 4.4429\n",
      "Epoch 8/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 898ms/step - accuracy: 0.0528 - loss: 4.3003 - val_accuracy: 0.0748 - val_loss: 4.3323\n",
      "Epoch 9/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 946ms/step - accuracy: 0.0694 - loss: 4.0890 - val_accuracy: 0.0787 - val_loss: 3.9898\n",
      "Epoch 10/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 860ms/step - accuracy: 0.0957 - loss: 3.7441 - val_accuracy: 0.1024 - val_loss: 3.6671\n",
      "Epoch 11/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 864ms/step - accuracy: 0.1254 - loss: 3.4704 - val_accuracy: 0.1496 - val_loss: 3.4861\n",
      "Epoch 12/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 863ms/step - accuracy: 0.1563 - loss: 3.2203 - val_accuracy: 0.1890 - val_loss: 3.1813\n",
      "Epoch 13/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 861ms/step - accuracy: 0.1865 - loss: 3.0168 - val_accuracy: 0.1890 - val_loss: 3.1019\n",
      "Epoch 14/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 872ms/step - accuracy: 0.2104 - loss: 2.8757 - val_accuracy: 0.2205 - val_loss: 2.8995\n",
      "Epoch 15/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 867ms/step - accuracy: 0.2559 - loss: 2.7069 - val_accuracy: 0.2362 - val_loss: 2.8879\n",
      "Epoch 16/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 863ms/step - accuracy: 0.2809 - loss: 2.5762 - val_accuracy: 0.2756 - val_loss: 2.6688\n",
      "Epoch 17/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 873ms/step - accuracy: 0.3133 - loss: 2.4279 - val_accuracy: 0.2756 - val_loss: 2.6291\n",
      "Epoch 18/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 859ms/step - accuracy: 0.3424 - loss: 2.2999 - val_accuracy: 0.2992 - val_loss: 2.5334\n",
      "Epoch 19/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 855ms/step - accuracy: 0.3921 - loss: 2.1375 - val_accuracy: 0.3228 - val_loss: 2.5174\n",
      "Epoch 20/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 862ms/step - accuracy: 0.4131 - loss: 2.0344 - val_accuracy: 0.3701 - val_loss: 2.3380\n",
      "Epoch 21/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 891ms/step - accuracy: 0.4564 - loss: 1.8814 - val_accuracy: 0.3780 - val_loss: 2.2197\n",
      "Epoch 22/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 935ms/step - accuracy: 0.4904 - loss: 1.7634 - val_accuracy: 0.3898 - val_loss: 2.1872\n",
      "Epoch 23/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 904ms/step - accuracy: 0.5190 - loss: 1.6428 - val_accuracy: 0.4134 - val_loss: 2.2003\n",
      "Epoch 24/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 908ms/step - accuracy: 0.5420 - loss: 1.5517 - val_accuracy: 0.5039 - val_loss: 1.9940\n",
      "Epoch 25/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 891ms/step - accuracy: 0.5895 - loss: 1.4252 - val_accuracy: 0.4843 - val_loss: 1.8689\n",
      "Epoch 26/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 863ms/step - accuracy: 0.5979 - loss: 1.3739 - val_accuracy: 0.4961 - val_loss: 1.8462\n",
      "Epoch 27/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 860ms/step - accuracy: 0.6248 - loss: 1.2960 - val_accuracy: 0.4882 - val_loss: 1.8987\n",
      "Epoch 28/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 853ms/step - accuracy: 0.6517 - loss: 1.2108 - val_accuracy: 0.5394 - val_loss: 1.7556\n",
      "Epoch 29/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 899ms/step - accuracy: 0.6511 - loss: 1.1530 - val_accuracy: 0.5118 - val_loss: 1.8398\n",
      "Epoch 30/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 898ms/step - accuracy: 0.6894 - loss: 1.0793 - val_accuracy: 0.5236 - val_loss: 1.7867\n",
      "Epoch 31/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 892ms/step - accuracy: 0.6986 - loss: 1.0060 - val_accuracy: 0.5197 - val_loss: 1.8184\n",
      "Epoch 32/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 892ms/step - accuracy: 0.7215 - loss: 0.9513 - val_accuracy: 0.5197 - val_loss: 1.7492\n",
      "Epoch 33/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 871ms/step - accuracy: 0.7316 - loss: 0.9266 - val_accuracy: 0.5630 - val_loss: 1.7212\n",
      "Epoch 34/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 861ms/step - accuracy: 0.7391 - loss: 0.8769 - val_accuracy: 0.5551 - val_loss: 1.7129\n",
      "Epoch 35/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 866ms/step - accuracy: 0.7605 - loss: 0.8363 - val_accuracy: 0.5472 - val_loss: 1.7064\n",
      "Epoch 36/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 875ms/step - accuracy: 0.7568 - loss: 0.8100 - val_accuracy: 0.5630 - val_loss: 1.7059\n",
      "Epoch 37/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 857ms/step - accuracy: 0.7815 - loss: 0.7538 - val_accuracy: 0.5630 - val_loss: 1.6537\n",
      "Epoch 38/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 852ms/step - accuracy: 0.7982 - loss: 0.6935 - val_accuracy: 0.5512 - val_loss: 1.7165\n",
      "Epoch 39/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 860ms/step - accuracy: 0.8069 - loss: 0.6644 - val_accuracy: 0.5984 - val_loss: 1.6552\n",
      "Epoch 40/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 856ms/step - accuracy: 0.8080 - loss: 0.6399 - val_accuracy: 0.5472 - val_loss: 1.6863\n",
      "Epoch 41/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 857ms/step - accuracy: 0.8170 - loss: 0.6267 - val_accuracy: 0.5945 - val_loss: 1.5878\n",
      "Epoch 42/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 860ms/step - accuracy: 0.8290 - loss: 0.5779 - val_accuracy: 0.5787 - val_loss: 1.5903\n",
      "Epoch 43/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 927ms/step - accuracy: 0.8363 - loss: 0.5631 - val_accuracy: 0.5709 - val_loss: 1.6713\n",
      "Epoch 44/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 941ms/step - accuracy: 0.8516 - loss: 0.5176 - val_accuracy: 0.5709 - val_loss: 1.6524\n",
      "Epoch 45/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 907ms/step - accuracy: 0.8454 - loss: 0.5163 - val_accuracy: 0.5787 - val_loss: 1.6910\n",
      "Epoch 46/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 936ms/step - accuracy: 0.8654 - loss: 0.4694 - val_accuracy: 0.5512 - val_loss: 1.6906\n",
      "Epoch 47/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 900ms/step - accuracy: 0.8730 - loss: 0.4373 - val_accuracy: 0.5945 - val_loss: 1.5715\n",
      "Epoch 48/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 907ms/step - accuracy: 0.8711 - loss: 0.4355 - val_accuracy: 0.5866 - val_loss: 1.6243\n",
      "Epoch 49/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 859ms/step - accuracy: 0.8761 - loss: 0.4231 - val_accuracy: 0.5787 - val_loss: 1.5945\n",
      "Epoch 50/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 891ms/step - accuracy: 0.8833 - loss: 0.3970 - val_accuracy: 0.6220 - val_loss: 1.5626\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_preprocessed,      # encoder input\n",
    "    y_train_encoded,           # target word labels\n",
    "    validation_data=(X_val_preprocessed, y_val_encoded),\n",
    "    batch_size=32,\n",
    "    epochs=50\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f4dbd46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - accuracy: 0.5748 - loss: 1.7449\n",
      "Test accuracy: 0.5748031735420227\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test_preprocessed, y_test_encoded)\n",
    "print(\"Test accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99daa11",
   "metadata": {},
   "source": [
    "### Before preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "50031cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original samples: 5568\n",
      "Original vocab size: 292\n",
      "Filtered samples: 5422\n",
      "Filtered vocab size: 146\n"
     ]
    }
   ],
   "source": [
    "# Count how many samples per word\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "label_counts = Counter(Dataset_glosses)\n",
    "\n",
    "MIN_SAMPLES = 2  # must be >=2 for stratification\n",
    "\n",
    "valid_labels = {\n",
    "    label for label, count in label_counts.items()\n",
    "    if count >= MIN_SAMPLES\n",
    "}\n",
    "\n",
    "print(\"Original samples:\", len(Dataset))\n",
    "print(\"Original vocab size:\", len(label_counts))\n",
    "\n",
    "# Filter dataset\n",
    "Dataset_filtered = []\n",
    "Glosses_filtered = []\n",
    "\n",
    "for x, y in zip(Dataset, Dataset_glosses):\n",
    "    if y in valid_labels:\n",
    "        Dataset_filtered.append(x)\n",
    "        Glosses_filtered.append(y)\n",
    "\n",
    "print(\"Filtered samples:\", len(Dataset_filtered))\n",
    "print(\"Filtered vocab size:\", len(set(Glosses_filtered)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "102fce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw, X_temp, y_train_raw, y_temp = train_test_split(\n",
    "    Dataset_filtered,\n",
    "    Glosses_filtered,\n",
    "    test_size=0.10,\n",
    "    random_state=42,\n",
    "    stratify=Glosses_filtered\n",
    ")\n",
    "\n",
    "X_val_raw, X_test_raw, y_val_raw, y_test_raw = train_test_split(\n",
    "    X_temp,\n",
    "    y_temp,\n",
    "    test_size=0.50,\n",
    "    random_state=42,\n",
    "    stratify=y_temp\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "49428353",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 64\n",
    "\n",
    "def pad_or_truncate(sequence, max_len=64):\n",
    "    T, D = sequence.shape\n",
    "    if T > max_len:\n",
    "        return sequence[:max_len]\n",
    "    elif T < max_len:\n",
    "        padding = np.zeros((max_len - T, D))\n",
    "        return np.vstack([sequence, padding])\n",
    "    return sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3fce4364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (4879, 64, 438)\n",
      "X_val shape: (271, 64, 438)\n",
      "X_test shape: (272, 64, 438)\n"
     ]
    }
   ],
   "source": [
    "X_train_raw = np.array([pad_or_truncate(seq, MAX_LEN) for seq in X_train_raw])\n",
    "X_val_raw   = np.array([pad_or_truncate(seq, MAX_LEN) for seq in X_val_raw])\n",
    "X_test_raw  = np.array([pad_or_truncate(seq, MAX_LEN) for seq in X_test_raw])\n",
    "\n",
    "print(\"X_train shape:\", X_train_raw.shape)  # (N, 64, D)\n",
    "print(\"X_val shape:\", X_val_raw.shape)  # (N, 64, D)\n",
    "print(\"X_test shape:\", X_test_raw.shape)  # (N, 64, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "628c13db",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "y_train = le.fit_transform(y_train_raw)\n",
    "y_val   = le.transform(y_val_raw)\n",
    "y_test  = le.transform(y_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9239dd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# =========================\n",
    "# PARAMETERS\n",
    "# =========================\n",
    "T = X_train_raw.shape[1]   # encoder timesteps\n",
    "D = X_train_raw.shape[2]   # feature dimension\n",
    "\n",
    "ENC_UNITS = 1000\n",
    "VOCAB_SIZE = 146    # number of target words (NOT glosses)\n",
    "\n",
    "# =========================\n",
    "# ENCODER ONLY MODEL\n",
    "# =========================\n",
    "encoder_inputs = Input(shape=(T, D), name=\"encoder_inputs\")\n",
    "\n",
    "# GRU encoder (return the last state)\n",
    "encoder_output = GRU(\n",
    "    ENC_UNITS,\n",
    "    dropout=0.2\n",
    ")(encoder_inputs)  # shape: (batch_size, ENC_UNITS)\n",
    "\n",
    "# Output layer for classification\n",
    "output = Dense(\n",
    "    VOCAB_SIZE,\n",
    "    activation='softmax'\n",
    ")(encoder_output)\n",
    "\n",
    "# Build model\n",
    "model_raw = Model(inputs=encoder_inputs, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "27763a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_16\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_16\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">157</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">438</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,320,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">132,132</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m157\u001b[0m, \u001b[38;5;34m438\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_16 (\u001b[38;5;33mGRU\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)           │     \u001b[38;5;34m4,320,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m132\u001b[0m)            │       \u001b[38;5;34m132,132\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,452,132</span> (16.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,452,132\u001b[0m (16.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,452,132</span> (16.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,452,132\u001b[0m (16.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_raw.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "20fe556c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 385ms/step - accuracy: 0.0172 - loss: 4.9813 - val_accuracy: 0.0258 - val_loss: 4.9330\n",
      "Epoch 2/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 375ms/step - accuracy: 0.0258 - loss: 4.9226 - val_accuracy: 0.0332 - val_loss: 4.9306\n",
      "Epoch 3/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 361ms/step - accuracy: 0.0324 - loss: 4.8085 - val_accuracy: 0.0221 - val_loss: 4.7359\n",
      "Epoch 4/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 366ms/step - accuracy: 0.0437 - loss: 4.5540 - val_accuracy: 0.0443 - val_loss: 4.5475\n",
      "Epoch 5/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 374ms/step - accuracy: 0.0432 - loss: 4.4424 - val_accuracy: 0.0517 - val_loss: 4.3821\n",
      "Epoch 6/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 369ms/step - accuracy: 0.0547 - loss: 4.3173 - val_accuracy: 0.0554 - val_loss: 4.2814\n",
      "Epoch 7/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 364ms/step - accuracy: 0.0549 - loss: 4.2020 - val_accuracy: 0.0590 - val_loss: 4.1903\n",
      "Epoch 8/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 380ms/step - accuracy: 0.0642 - loss: 4.1096 - val_accuracy: 0.0701 - val_loss: 4.1407\n",
      "Epoch 9/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 365ms/step - accuracy: 0.0791 - loss: 3.9941 - val_accuracy: 0.0812 - val_loss: 3.9316\n",
      "Epoch 10/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 367ms/step - accuracy: 0.0947 - loss: 3.8653 - val_accuracy: 0.0923 - val_loss: 3.9602\n",
      "Epoch 11/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.1064 - loss: 3.7371 - val_accuracy: 0.1218 - val_loss: 3.7001\n",
      "Epoch 12/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 378ms/step - accuracy: 0.1277 - loss: 3.5908 - val_accuracy: 0.1402 - val_loss: 3.5529\n",
      "Epoch 13/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 379ms/step - accuracy: 0.1357 - loss: 3.4946 - val_accuracy: 0.1255 - val_loss: 3.4701\n",
      "Epoch 14/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 359ms/step - accuracy: 0.1570 - loss: 3.3811 - val_accuracy: 0.1402 - val_loss: 3.3307\n",
      "Epoch 15/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 364ms/step - accuracy: 0.1627 - loss: 3.2924 - val_accuracy: 0.1882 - val_loss: 3.3046\n",
      "Epoch 16/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 361ms/step - accuracy: 0.1834 - loss: 3.2088 - val_accuracy: 0.1661 - val_loss: 3.2847\n",
      "Epoch 17/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 361ms/step - accuracy: 0.1998 - loss: 3.1325 - val_accuracy: 0.1771 - val_loss: 3.2023\n",
      "Epoch 18/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 361ms/step - accuracy: 0.2089 - loss: 3.0670 - val_accuracy: 0.2030 - val_loss: 3.1584\n",
      "Epoch 19/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 366ms/step - accuracy: 0.2404 - loss: 2.9608 - val_accuracy: 0.2066 - val_loss: 3.1127\n",
      "Epoch 20/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 358ms/step - accuracy: 0.2488 - loss: 2.8907 - val_accuracy: 0.2362 - val_loss: 3.0168\n",
      "Epoch 21/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 366ms/step - accuracy: 0.2640 - loss: 2.8418 - val_accuracy: 0.2177 - val_loss: 3.0055\n",
      "Epoch 22/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 360ms/step - accuracy: 0.2740 - loss: 2.7589 - val_accuracy: 0.2472 - val_loss: 2.9830\n",
      "Epoch 23/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 358ms/step - accuracy: 0.2884 - loss: 2.6773 - val_accuracy: 0.2546 - val_loss: 2.8560\n",
      "Epoch 24/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 358ms/step - accuracy: 0.3023 - loss: 2.5859 - val_accuracy: 0.2288 - val_loss: 2.8553\n",
      "Epoch 25/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 360ms/step - accuracy: 0.3257 - loss: 2.5143 - val_accuracy: 0.2694 - val_loss: 2.7516\n",
      "Epoch 26/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 363ms/step - accuracy: 0.3439 - loss: 2.4550 - val_accuracy: 0.2878 - val_loss: 2.7261\n",
      "Epoch 27/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 365ms/step - accuracy: 0.3575 - loss: 2.3791 - val_accuracy: 0.2952 - val_loss: 2.7888\n",
      "Epoch 28/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 357ms/step - accuracy: 0.3841 - loss: 2.2848 - val_accuracy: 0.3063 - val_loss: 2.6236\n",
      "Epoch 29/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 358ms/step - accuracy: 0.4013 - loss: 2.2390 - val_accuracy: 0.3395 - val_loss: 2.5740\n",
      "Epoch 30/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 360ms/step - accuracy: 0.4255 - loss: 2.1498 - val_accuracy: 0.2878 - val_loss: 2.6174\n",
      "Epoch 31/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 365ms/step - accuracy: 0.4261 - loss: 2.1147 - val_accuracy: 0.3100 - val_loss: 2.5568\n",
      "Epoch 32/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 365ms/step - accuracy: 0.4423 - loss: 2.0560 - val_accuracy: 0.3247 - val_loss: 2.5936\n",
      "Epoch 33/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 359ms/step - accuracy: 0.4552 - loss: 1.9934 - val_accuracy: 0.3542 - val_loss: 2.5054\n",
      "Epoch 34/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 365ms/step - accuracy: 0.4653 - loss: 1.9469 - val_accuracy: 0.3432 - val_loss: 2.4920\n",
      "Epoch 35/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 361ms/step - accuracy: 0.4782 - loss: 1.8876 - val_accuracy: 0.3321 - val_loss: 2.4728\n",
      "Epoch 36/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 360ms/step - accuracy: 0.4966 - loss: 1.8353 - val_accuracy: 0.3579 - val_loss: 2.4210\n",
      "Epoch 37/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 359ms/step - accuracy: 0.4972 - loss: 1.7919 - val_accuracy: 0.3727 - val_loss: 2.3820\n",
      "Epoch 38/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 359ms/step - accuracy: 0.5173 - loss: 1.7110 - val_accuracy: 0.3653 - val_loss: 2.3714\n",
      "Epoch 39/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 361ms/step - accuracy: 0.5386 - loss: 1.6751 - val_accuracy: 0.3727 - val_loss: 2.3822\n",
      "Epoch 40/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 353ms/step - accuracy: 0.5581 - loss: 1.6027 - val_accuracy: 0.3653 - val_loss: 2.4004\n",
      "Epoch 41/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 357ms/step - accuracy: 0.5550 - loss: 1.5787 - val_accuracy: 0.3948 - val_loss: 2.3379\n",
      "Epoch 42/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 360ms/step - accuracy: 0.5745 - loss: 1.5339 - val_accuracy: 0.4022 - val_loss: 2.2712\n",
      "Epoch 43/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 360ms/step - accuracy: 0.5929 - loss: 1.4775 - val_accuracy: 0.3838 - val_loss: 2.2616\n",
      "Epoch 44/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 359ms/step - accuracy: 0.6018 - loss: 1.4470 - val_accuracy: 0.3764 - val_loss: 2.3012\n",
      "Epoch 45/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 361ms/step - accuracy: 0.6167 - loss: 1.3882 - val_accuracy: 0.3875 - val_loss: 2.2997\n",
      "Epoch 46/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 354ms/step - accuracy: 0.6255 - loss: 1.3511 - val_accuracy: 0.3690 - val_loss: 2.3830\n",
      "Epoch 47/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 359ms/step - accuracy: 0.6276 - loss: 1.3270 - val_accuracy: 0.3690 - val_loss: 2.4034\n",
      "Epoch 48/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 363ms/step - accuracy: 0.6358 - loss: 1.3087 - val_accuracy: 0.3985 - val_loss: 2.2717\n",
      "Epoch 49/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 362ms/step - accuracy: 0.6575 - loss: 1.2499 - val_accuracy: 0.4096 - val_loss: 2.3526\n",
      "Epoch 50/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 375ms/step - accuracy: 0.6639 - loss: 1.2241 - val_accuracy: 0.3838 - val_loss: 2.3456\n"
     ]
    }
   ],
   "source": [
    "history = model_raw.fit(\n",
    "    X_train_raw,      # encoder input\n",
    "    y_train,           # target word labels\n",
    "    validation_data=(X_val_raw, y_val),\n",
    "    batch_size=32,\n",
    "    epochs=50\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6f4b55e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.4706 - loss: 2.1804\n",
      "Test accuracy: 0.47058823704719543\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model_raw.evaluate(X_test_raw, y_test)\n",
    "print(\"Test accuracy:\", test_acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sign_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
